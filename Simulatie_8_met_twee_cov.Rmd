---
title: "Simulatie"
output: html_document
date: '2023'
---

## Initializations

```{r eval = FALSE}
library(stringr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(data.table)
library(ExPosition)
library(gridExtra)
library(gdata)
library(rcompanion)

options(dplyr.summarise.inform = FALSE)

#poging 1:met treemilc nieuw
load("F:/Documents/Thesis/Simulatie/Simulatie_8_met_twee_cov/Simulatie_8_met_twee_cov.RData") #hier zitten de goeie LC en LCT in
save.image("F:/Documents/Thesis/Simulatie/Simulatie_8_met_twee_cov/Simulatie_8_met_twee_cov_10000.RData")

#poging 2
load("F:/Documents/Thesis/Simulatie/Simulatie_8_met_twee_cov/Simulatie_8_met_twee_cov.RData")

cramerV(table(simDat2_iteration3[simDat2_iteration3$Y1!=2,]$SBIgroep,simDat2_iteration3[simDat2_iteration3$Y1!=2,]$Y1)) #0.3
cramerV(table(simDat2_iteration3[simDat2_iteration3$Y1!=2,]$baanduur,simDat2_iteration3[simDat2_iteration3$Y1!=2,]$Y1)) #0.42

setwd("F:/Documents/Thesis/Simulatie/Simulatie_8_met_twee_cov/")

library(gdata)
keep(ab,ba,sure=TRUE)

```


## True proportions in simulated data

```{r eval = FALSE}
true_proportions = c(0.6178, 0.2473, 0.1349)
names(true_proportions) = c("Vast","Overig","Flex")
```


## Function to create a matrix with the (real) measurement error probabilities used to simulate data

@param a2,...b32 (int): Logit parameters used to simulate the data

@returns matrix (matrix): Matrix with measurement error probabilities

```{r}
create_ME_matrix = function(a2,a3,b22,b33,b23,b32){
  row1 = c(1/(1+exp(a2)+exp(a3)),exp(a2)/(1+exp(a2)+exp(a3)),exp(a3)/(1+exp(a2)+exp(a3)))
  row2 = c(1/(1+exp(a2+b22)+exp(a3+b32)),exp(a2+b22)/(1+exp(a2+b22)+exp(a3+b32)),exp(a3+b32)/(1+exp(a2+b22)+exp(a3+b32)))
  row3 = c(1/(1+exp(a2+b23)+exp(a3+b33)),exp(a2+b23)/(1+exp(a2+b23)+exp(a3+b33)),exp(a3+b33)/(1+exp(a2+b23)+exp(a3+b33)))
  matrix = matrix(c(row1,row2,row3),nrow=3,ncol=3,byrow=TRUE)
  return(matrix)
}
```

```{r}
#Create ME matrices in global environment
ME_matrix1 = create_ME_matrix(-log(18),-log(18),log(324),log(324),log(18),log(18)) #10% measurement error
ME_matrix2 = create_ME_matrix(-3*log(2),-3*log(2),6*log(2),6*log(2),3*log(2),3*log(2)) #20% measurement error
ME_matrix3 = create_ME_matrix(-1.54045,-1.54045,3.0809,3.0809,1.54045,1.54045) #30% measurement error
ME_matrix4a = create_ME_matrix(-4.4917,-4.94368,7.64123,5.6678,3.09876,4.55064)
ME_matrix4b = create_ME_matrix(-6.14311,-2.63157,11.9482,5.03275,1.72427,1.53296)
ME_matrix4 = list(ME_matrix4a,ME_matrix4b)
```


## Function to generate a data set

@param seed (int): Seed for generating a data set
@param ME (int): Factor representing the degree of measurement error (1=0.1, 2=0.2, 3=0.3, 4=realistic)
@param folder (string): Folder to save files in

@returns (data.frame): A simulated data set of size N=10,000 with the indicated degree of measurement error

```{r}
simulate_data = function(seed, ME, folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\"){
  
  #Create Latent Gold script for LC
  
  #exampleDat.dat voor N=1,000
  filepath_input = paste0(folder,"exampleDat.dat")

  script_part1 = paste0("version = 6.0\ninfile '",filepath_input,"' \n\nmodel
    title 'simulation",ME,"';
    options
    algorithm
        tolerance=1e-08 emtolerance=0.01 emiteration=500 nriterations=500;
    startvalues
        seed=1 sets=100 tolerance=1e-05 iterations=100;
    montecarlo
        seed=1 replicates=500 tolerance=1e-008;
    bayes
        categorical=1 variances=1 latent=1 poisson=1;
    missing includeall;
    output       
    	parameters=first standarderrors profile reorderclasses iterationdetails;\n")

  #Specify parameter estimates
  contract = c(0.8252, -0.3192)
  q = c(-0.1506, -0.1584) 
  SBIgroep = c(-2.5392, 2.2426)
  baanduur = c(-4.6105, -3.4073)
  data_param = gsub(",","",toString(c(contract,q,SBIgroep,baanduur)))

  #Parameters for 10% measurement error
  if(ME==1){
    outfile_name = paste0("simDat1_iteration",seed,".dat")
    a2=a3=-log(18)  #Coefficients for measurement error matrix
    b22=b33=log(324)
    b32=b23=log(18)
    ME_coefs = c(a2,a3,b22,b32,b23,b33,"\n")
    ME_coefs = gsub(",","",toString(rep(ME_coefs,3)))
    parameters = paste("\n",data_param,"\n",ME_coefs,"}\nend model")
  }

  #Parameters for 20% measurement error
  else if(ME==2){
    outfile_name = paste0("simDat2_iteration",seed,".dat")
    a2=a3=-3*log(2) #Coefficients for measurement error matrix
    b22=b33=6*log(2)
    b32=b23=3*log(2)
    ME_coefs = c(a2,a3,b22,b32,b23,b33,"\n")
    ME_coefs = gsub(",","",toString(rep(ME_coefs,3)))
    parameters = paste("\n",data_param,"\n",ME_coefs,"}\nend model")
  }
  
  #Parameters for 30% measurement error
  else if(ME==3){
    outfile_name = paste0("simDat3_iteration",seed,".dat")
    a2=a3=-1.54045 #Coefficients for measurement error matrix
    b22=b33=3.0809
    b32=b23=1.54045
    ME_coefs = c(a2,a3,b22,b32,b23,b33,"\n")
    ME_coefs = gsub(",","",toString(rep(ME_coefs,3)))
    parameters = paste("\n",data_param,"\n",ME_coefs,"}\nend model")
  }

  #Parameters for realistic amount of measurement error
  else if(ME==4){
    outfile_name = paste0("simDat4_iteration",seed,".dat")
    Y1_a2= -4.4917
    Y1_a3= -4.94368
    Y1_b22=7.64123
    Y1_b32=4.55064
    Y1_b23=3.09876
    Y1_b33=5.6678
    Y2_a2=-6.14311
    Y2_a3=-2.63157
    Y2_b22=11.9482
    Y2_b32=1.53296
    Y2_b23=1.72427
    Y2_b33=5.03275
    ME_coefs_Y1 = c(Y1_a2,Y1_a3,Y1_b22,Y1_b32,Y1_b23,Y1_b33,"\n")
    ME_coefs_Y2 = c(Y2_a2,Y2_a3,Y2_b22,Y2_b32,Y2_b23,Y2_b33,"\n")
    ME_coefs = gsub(",","",toString(rep(c(ME_coefs_Y1,ME_coefs_Y2,ME_coefs_Y1),1))) 
    parameters = paste(data_param,"\n",ME_coefs,"}\nend model")
  }
  
  script_part2 = paste0("\toutfile '",outfile_name, "' simulation=1 seed=",seed,";
    variables
         caseid id;
         caseweight w;
         dependent Y1 nominal 3, Y2 nominal 3, Y3 nominal 3;
         independent q nominal, SBIgroep nominal, baanduur nominal;
         latent cluster nominal 3;
     equations
         cluster <- 1 + q + SBIgroep + baanduur;			
         Y1      <- 1 + cluster;	
         Y2      <- 1 + cluster;
         Y3      <- 1 + cluster;
{ ")
  
  #Combine parts of script
  script = paste0(script_part1,script_part2,parameters)
  writeLines(script, paste0(folder,"simDat",ME,"_iteration",seed,"_script.lgs"))
  
  #Execute Latent Gold script
  shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', folder, paste0("simDat",ME,"_iteration",seed,"_script.lgs"), ' /b'))

  #Import simulated data set
  simDat = as.data.frame(fread(outfile_name,dec=","))
  
  #To add extra 'problem covariate' category, get id of observations with contract 'other' in Y1
  id_other_Y1 = simDat[simDat$Y1==2,]$id   
  
  #Select a random 90% of these observations (as in the real data)
  id_add_extra_cat = sample(id_other_Y1,(0.9*length(id_other_Y1))) 
  
  #Find out how many categories both covariates have
  ncat1 = length(levels(factor(simDat[,which(names(simDat)=="baanduur")]))) 
  ncat2 = length(levels(factor(simDat[,which(names(simDat)=="SBIgroep")]))) 
  
  #Assign the selected observations to a new covariate category
  simDat[id_add_extra_cat,which(names(simDat)=="baanduur")] = ncat1 + 1  
  simDat[id_add_extra_cat,which(names(simDat)=="SBIgroep")] = ncat2 + 1   
  
  return(simDat)
}

# t = simulate_data(1,1)

```


## Helpfunction to create a subset of the right size and with the correct amount of measurement error for each analysis

@param iteration (int): Iteration number (to get a different data set for each of the 10 iterations per model)
@param ind (int): Number of indicators
@param cov_ok (string): Covariate name that is not problematic (i.e. NULL or "q")
@param cov_problem (string or vector): String or vector of covariate names that are problematic (i.e. NULL, "baanduur", "SBIgroep" or c("baanduur" or "SBIgroep")
@param N (int): Size of the data set
@param ME (int): Factor representing the degree of measurement error (1=0.2, 2=0.3, 3=0.5, 4=realistic)

@returns (data.frame): A subset of the right size and with the correct amount of measurement error as indicated

```{r}
create_subset = function(iteration, ind, cov_ok, cov_problem, N, ME){
  
  #If a certain data set does not exist, create it  
  if(!exists(paste0("simDat",ME,"_iteration",iteration))){
    assign(paste0("simDat",ME,"_iteration",iteration),simulate_data(iteration,ME),envir=globalenv())
  }
  
  data = get(paste0("simDat",ME,"_iteration",iteration))
  
  #Set seed to get the same data set for every model within each iteration
  set.seed(iteration) 
  select_cases = sample(1:nrow(data),N,replace=FALSE)
  
  #Select columns to return (i.e. remove some redundant columns)
  all_ind = c("Y1","Y2","Y3","Y4")
  ind = all_ind[1:ind]

  subset = data[select_cases,c("id",ind,cov_ok,cov_problem)]
  
  return(subset)
}
```


## Helpfunction to generate a Latent Gold script 

@param type (string): String indicating what type of script is generated (e.g. "LC" for regular LC and "LCT" for LCT step 2) 
@param ind (int): Number of indicators
@param cov_ok (string): Covariate name that is not problematic (i.e. NULL or "q")
@param cov_problem (string or vector): String or vector of covariate names that are problematic (i.e. NULL, "baanduur", "SBIgroep" or c("baanduur" or "SBIgroep")
@param N (int): Size of data set
@param model_name (string): Name of the model
@param filepath_input (string):
@param filepath_output (string):

@returns (string): A string containing a Latent Gold script

```{r}
generate_script = function(type, ind, cov_ok, cov_problem, N, model_name, dat, filepath_input, filepath_output){

  #Create vectors with characters to use for restrictions later on
  pars = c("aa","bb","cc","dd","ee","ff","gg","hh","ii","jj")
  pars2 = c("kk","ll","mm","nn","oo","pp","qq","rr","ss","tt")
  pars_count = pars2_count = 0

  script_part1 = paste0("version = 6.0\ninfile '",filepath_input,"' \n\nmodel title '")

  #Let the number of sets of starting values depend on the size of the data set
  if(N<10000){
    sets = 3200
  } else {
    sets = 100
  }
  
  script_part2 = paste0("';
    options
    algorithm
        tolerance=1e-08 emtolerance=0.01 emiterations=10000000 nriterations=10000000;
    startvalues
        seed=1 sets=",sets," tolerance=1e-05 iterations=100;
    bayes
        categorical=1 variances=1 latent=1 poisson=1;
    missing includeall;
    output
    	parameters=")

  script_part3 = paste0("first standarderrors profile reorderclasses iterationdetails;
    	outfile '",filepath_output,"' classification keep=id;
    variables\n") 
     
  #Adjust some parameters depending on what type of analysis is performed
  if(type=="LC"){
    latent_var = paste0("\n\tlatent Cluster nominal 3;
    equations\n")
  } else {
    latent_var = paste0("\n\tlatent Cluster nominal 2;
    equations\n")
  }
  if(type=="LCT"){
    caseweight = "caseweight p1;\n"
  } else {
    caseweight = ""
  }
  
  #Adjust equations depending on the number of indicators
  if(ind==2){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal;"
    dep_ind_eq2 = "\n\tY2 <- 1 | Cluster;"
  } else if(ind==3){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal, Y3 nominal;"
    dep_ind_eq2 = "\n\tY2 <- 1 | Cluster;\n\tY3 <- 1 | Cluster;"
  } else if(ind==4){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal, Y3 nominal, Y4 nominal;"
    dep_ind_eq2 = "\n\tY2 <- 1 | Cluster;\n\tY3 <- 1 | Cluster;\n\tY4 <- 1 | Cluster;"
  }
  
  #Adjust equations (and restrictions) depending on which covariates to include (if any)
  cov = c(cov_ok, cov_problem)
  restrictions1 = restrictions2 = ""
  dep_cov = ifelse(is.null(cov),"","\n\tindependent ")
  dep_ind_eq1 = "\n\tY1 <- 1 | Cluster"
 
  if(!is.null(cov)){
    for(i in 1:length(cov)){
      if(i==1){
        dep_cov = paste0(dep_cov," ",cov[i]," nominal")
      } else {
        dep_cov = paste0(dep_cov,", ",cov[i]," nominal")
      }
    }
    dep_cov = paste0(dep_cov,";")
  }
  
  latent_var_eq = "\tCluster <- 1"
  
  if(!is.null(cov_ok)){
    for(i in 1:length(cov_ok)){
      latent_var_eq = paste(latent_var_eq,"+",cov_ok[i])
    }
  }
  
  if(!is.null(cov_problem)){
    for(i in 1:length(cov_problem)){
      pars_count = pars_count + 1
      which_col = which(colnames(dat)==cov_problem[i])
      num_cats = length(levels(factor(dat[,which_col])))
      dep_ind_eq1 = paste0(dep_ind_eq1," + (",pars[i],"~ful) 1 | ",cov_problem[i])
      latent_var_eq = paste0(latent_var_eq," + (",pars2[i],") ",cov_problem[i])
      
      for(j in 1:num_cats){
        if(j!=num_cats){
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",] = 0;")
        } else{
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",1] = -100;")
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",2] = 0;")
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",3] = -100;")
        }
      }   
      
      if(length(cov_problem)>1&(i>1)){
        par2 = (num_cats-1)*2
        par1 = par2-1
        if(type=="LC"){
          restrictions1 = paste0(restrictions1,paste0("\n\t",pars2[i],"[1,",par1,"] = 0; ",pars2[i],"[1,",par2,"] = 0;"))
        } else {
          restrictions1 = paste0(restrictions1,paste0("\n\t",pars2[i],"[1,",num_cats-1,"] = 0;"))
        }
      }
    }
  }
  
  latent_var_eq = paste0(latent_var_eq,";")
  dep_ind_eq1 = paste0(dep_ind_eq1,";")
  
  
  #Combine all parts of the script
  script=paste0(script_part1,model_name,script_part2,script_part3,caseweight,dep_ind,dep_cov,
                latent_var,latent_var_eq,dep_ind_eq1,dep_ind_eq2,restrictions1,restrictions2,"\nend model")
  return(script)
}

```



```{r}
generate_script_treeMILC_step1 = function(type, ind, cov_ok, cov_problem, model_name, dat, filepath_input, filepath_output,par){
  
  #Create vectors with characters to use for restrictions later on
  pars = c("aa","bb","cc","dd","ee","ff","gg","hh","ii","jj")
  pars_count  = 0
  
  script_part1 = paste0("version = 6.0\ninfile '",filepath_input,"' \n\nmodel title '")
  
  script_part2 = paste0("';
    options
    algorithm
        tolerance=1e-08 emtolerance=0.01 emiterations=0 nriterations=0;
    startvalues
        seed=1 sets=100 tolerance=1e-05 iterations=100;
    bayes
        categorical=1 variances=1 latent=1 poisson=1;
    missing includeall;
    output
    	parameters=")
  
  script_part3 = paste0("first standarderrors profile reorderclasses iterationdetails;
    	outfile '",filepath_output,"' classification keep=id;
    variables\n") 
  
  #Adjust some parameters depending on what type of analysis is performed
  if(type=="LC"){
    latent_var = paste0("\n\tlatent Cluster nominal 3;
    equations\n")
  } else {
    latent_var = paste0("\n\tlatent Cluster nominal 2;
    equations\n")
  }
  if(type=="LCT"){
    caseweight = "caseweight p1;\n"
  } else {
    caseweight = ""
  }
  
  #Adjust equations (and restrictions) depending on which covariates to include (if any)
  cov = c(cov_ok, cov_problem)
  restrictions = restrictions2 = ""
  latent_var_eq = "\tCluster <- (zz) 1"
  dep_cov = ifelse(is.null(cov),"","\n\tindependent ")
  dep_ind_eq1 = "\n\tY1 <- (jj) 1 | Cluster"
  
  if(!is.null(cov_problem)){
    for(i in 1:length(cov_problem)){
      pars_count = pars_count + 1
      which_col = which(colnames(dat)==cov_problem[i])
      num_cats = length(levels(factor(dat[,which_col])))
      dep_ind_eq1 = paste0(dep_ind_eq1," + (",pars[i],"~ful) 1 | ",cov_problem[i])

      for(j in 1:num_cats){
        if(j!=num_cats){
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",] = 0;")
        } else{
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",1] = -100;")
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",2] = 0;")
          restrictions2 = paste0(restrictions2,"\n\t",pars[i],"[",j,",3] = -100;")
        }
      }   
    }
  }

  
  if(!is.null(cov)){
    for(i in 1:length(cov)){
      if(i==1){
        dep_cov = paste0(dep_cov," ",cov[i]," nominal")
      } else {
        dep_cov = paste0(dep_cov,", ",cov[i]," nominal")
      }
    }
    dep_cov = paste0(dep_cov,";")
  }  

  restrictions = paste0(restrictions,"\n\tzz[1,1] ~= ",par[1,]$coef,";\n")
  restrictions = paste0(restrictions,"\tzz[1,2] ~= ",par[2,]$coef,";\n")
  
  df_counter = 2

  if(!is.null(cov)){
    for(i in 1:length(cov)){
      which_col = which(colnames(dat)==cov[i])
      num_cats = length(levels(factor(dat[,which_col])))
      pars_count = pars_count + 1
      latent_var_eq = paste0(latent_var_eq," + (",pars[pars_count],") ",cov[i])
      par2 = (num_cats-1)*2

      for(j in 1:par2){
        df_counter = df_counter + 1
        if(par[df_counter,]$coef==0){
          restrictions = paste0(restrictions,"\t",pars[pars_count],"[1,",j,"] = ",par[df_counter,]$coef,";\n")
        } else {
          restrictions = paste0(restrictions,"\t",pars[pars_count],"[1,",j,"] ~= ",par[df_counter,]$coef,";\n")
        }
      }
    }
  }
  
  #Adjust equations depending on the number of indicators
  if(ind==2){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal;"
    dep_ind_eq2 = "\n\tY2 <- (kk) 1 | Cluster;"
  } else if(ind==3){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal, Y3 nominal;"
    dep_ind_eq2 = "\n\tY2 <- (kk) 1 | Cluster;\n\tY3 <- (ll) 1 | Cluster;"
  } else if(ind==4){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal, Y3 nominal, Y4 nominal;"
    dep_ind_eq2 = "\n\tY2 <- (kk) 1 | Cluster;\n\tY3 <- (ll) 1 | Cluster;\n\tY4 <- (mm) 1 | Cluster;"
  }

  all_indicators = c("Y1","Y2","Y3","Y4")
  indicators_parname = c("jj","kk","ll","mm")
  for(i in 1:ind){
    df_counter = grep(all_indicators[i],par$term1)[1]
    restrictions = paste0(restrictions,"\t",indicators_parname[i],"[1,1] ~= ",par[df_counter,]$coef,";\n")
    restrictions = paste0(restrictions,"\t",indicators_parname[i],"[1,2] ~= ",par[df_counter+1,]$coef,";\n")
    restrictions = paste0(restrictions,"\t",indicators_parname[i],"[2,1] ~= ",par[df_counter+2,]$coef,";\n")
    restrictions = paste0(restrictions,"\t",indicators_parname[i],"[2,2] ~= ",par[df_counter+3,]$coef,";\n")
    restrictions = paste0(restrictions,"\t",indicators_parname[i],"[3,1] ~= ",par[df_counter+4,]$coef,";\n")
    restrictions = paste0(restrictions,"\t",indicators_parname[i],"[3,2] ~= ",par[df_counter+5,]$coef,";\n")
  }
  
  latent_var_eq = paste0(latent_var_eq,";")
  dep_ind_eq1 = paste0(dep_ind_eq1,";")
  
  
  #Combine all parts of the script
  script=paste0(script_part1,model_name,script_part2,script_part3,caseweight,dep_ind,dep_cov,
                latent_var,latent_var_eq,dep_ind_eq1,dep_ind_eq2,restrictions,restrictions2,"\nend model")
  return(script)
}

# t = generate_script_treeMILC_step1("LC", 3,NULL, c("SBIgroep"), 1000, "model_name", simDat1_iteration1, "filepath_input", "filepath_output",test.dat)
# writeLines(t,"F:/Documents/Thesis/Simulatie/Voorbeeld/test.lgs")

```


## Helpfunction to assign the right cluster names to the right clusters 

@param results (list): Results of one particular LC, LCT or tree-MILC model

@returns (list): Same object as input, but with corrected cluster assignment if necessary 

```{r}
fix_cluster_assignment = function(type=NULL,results){
  
  #Get a list of matrices with measurement error per indicator
  ME_list = get_ME(results)
  
  #Create one matrix that contains the average values of all matrices
  summed_matrices = ME_list[[1]]
  for(j in 2:length(ME_list)){
    summed_matrices = summed_matrices + ME_list[[j]]
  }
  mean_matrix = summed_matrices/length(ME_list)
  
  #Find diagonal combinations of cluster names and store them in a data frame
  all_diagonals=data.frame()
  
  if(type=="LC"){ #Find all possible diagonal combinations
    for(i in 1:3){
      for(j in 1:3){
       for(k in 1:3)
        if(length(unique(c(i,j,k)))==3){
          all_diagonals=rbind(all_diagonals,c(i,j,k,mean_matrix[i,1],mean_matrix[j,2],mean_matrix[k,3],
                                              sum(mean_matrix[i,1],mean_matrix[j,2],mean_matrix[k,3])))
        }
      }
    }
  }
  else { #For non-LC models: only find combinations for switched 1 and 3's, because 2 is already correct
    all_diagonals = rbind(all_diagonals,c(1,2,3,mean_matrix[1,1],mean_matrix[2,2],mean_matrix[3,3],sum(mean_matrix[1,1],mean_matrix[2,2],mean_matrix[3,3])))
  all_diagonals = rbind(all_diagonals,c(3,2,1,mean_matrix[3,1],mean_matrix[2,2],mean_matrix[1,3],sum(mean_matrix[3,1],mean_matrix[2,2],mean_matrix[1,3])))
  }
  
  colnames(all_diagonals)=c("1","2","3","d1","d2","d3","sum")
  
  #Find out which combination of diagonals yields the highest sum of diagonal values
  which_max = which.max(as.vector(all_diagonals[,7]))

  #Find out how to reassign clusters
  max_1=all_diagonals[which_max,1]
  max_2=all_diagonals[which_max,2]
  max_3=all_diagonals[which_max,3]
  reassignment = c(as.numeric(max_1),as.numeric(max_2),as.numeric(max_3))

  #If clusters need not to be reassigned, return original results
  if(identical(reassignment,c(1,2,3))){
     return(results)
  } 
  else {
    #Create a list to store the corrected results in (same format as input)
    to_return = list(results[[1]])
    results = results[[2]]
    
    #Store the original posterior probabilities temporarily in a data frame 
    posteriors = data.frame(p1=results$p1,p2=results$p2,p3=results$p3)
    results$p1=posteriors[,max_1]
    results$p2=posteriors[,max_2]
    results$p3=posteriors[,max_3]
    to_return = append(to_return,list(results))
    return(to_return)
  }
}

```


#Fix cluster bootstrap

```{r}
fix_cluster_bootstrap = function(boot_results) {
  table = table(boot_results$Y2,boot_results$cluster)
  prop_table = prop.table(table, margin = 1)
  
  all_diagonals = data.frame()
  all_diagonals = rbind(all_diagonals,c(1,2,3,prop_table[1,1],prop_table[2,2],prop_table[3,3],sum(prop_table[1,1],prop_table[2,2],prop_table[3,3])))
  all_diagonals = rbind(all_diagonals,c(3,2,1,prop_table[3,1],prop_table[2,2],prop_table[1,3],sum(prop_table[3,1],prop_table[2,2],prop_table[1,3])))
  
  colnames(all_diagonals)=c("1","2","3","d1","d2","d3","sum")

  #Find out which combination of diagonals yields the highest sum of diagonal values
  which_max = which.max(as.vector(all_diagonals[,7]))

  #Find out how to reassign clusters
  max_1=all_diagonals[which_max,1]
  max_3=all_diagonals[which_max,3]
  reassignment = c(max_1,max_3)
  
  if(identical(reassignment,c(1,3))){
     return(boot_results)
  } else {
     boot_results$new_cluster = NA
     boot_results[boot_results$cluster==max_1,]$new_cluster = 1
     boot_results[boot_results$cluster==2,]$new_cluster = 2
     boot_results[boot_results$cluster==max_3,]$new_cluster = 3
     boot_results$cluster = boot_results$new_cluster
     boot_results = boot_results[,-which(colnames(boot_results)=="new_cluster")]
  }
  
  return(boot_results)
}
```



## Helpfunction to fix scientific number notation in Latent Gold output

```{r}
fix_number_notation = function(vector){
  
  if(is.numeric(vector)){
    return(vector)
  }
  else {

    return_vec = rep(NA,length(vector))
    for(i in 1:length(vector)){
      removed_spaces = gsub(" ", "", vector[i])
      split_vec = str_split(removed_spaces, "e-")
      
      if(length(split_vec[[1]])>1){
        nominator = as.numeric(gsub(",", ".", split_vec[[1]][1]))
        denominator = as.numeric(split_vec[[1]][2])
        final_number = nominator/(10^denominator)
        return_vec[i] = final_number
      } else {
        temp_string = gsub(",", ".", split_vec[[1]][1])
        if(temp_string=="."){
          return_vec[i] = 0
        } else { 
           return_vec[i] = as.numeric(gsub(",", ".", split_vec[[1]][1]))
        }
      }
    }
    return(return_vec)
  }
}

```


## Store model info


```{r}
store_model_info = function(iteration, ind, cov_ok, cov_problem, N, ME){

  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1,  cov_problem1, N, ME, sep="-")
  model_info1 = data.frame(iteration=iteration,ind=ind,cov_ok=cov_ok1,cov_problem=cov_problem1)
  model_info2 = data.frame(N=N,ME=ME,id=model_name)
  model_info = cbind(model_info1,model_info2)
  
  to_return = list(model_info) 

  return(to_return)
}

```


## Function to _perform_tre LC

@param iteration (int): Iteration number 
@param ind (int): Number of indicators
@param cov (int): If int: Number of covariates, if vector: Names of covariates to include
@param N (int): Size of data set
@param ME (int): Factor representing the degree of measurement error probabilities (1=0.2, 2=0.3, 3=0.5, 4=realistic)
@param folder (string): Folder to save files in

@returns (list): A list that consists of:
[[1]] Data frame with an overview of model parameters (iteration, ind, cov, N, ME)
[[2]] Data frame with model results (posterior probabilities and cluster classification for each observation)

```{r}
perform_lc = function(iteration, ind, cov_ok, cov_problem, N, ME, dat = NULL,folder="F:\\Documents\\Thesis\\Simulatie\\Voorbeeld\\"){

  #Store model information
  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1,  cov_problem1, N, ME, sep="-")
  to_return = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)

  #Write data set to use to file
  if(is.null(dat)){
    dat = create_subset(iteration,ind,cov_ok,cov_problem,N,ME)
  }
  else {
    dat = dat
  }

  filepath_input = paste0(folder,"LC_",model_name,"_data.dat")
  fwrite(dat,file=filepath_input,sep="\t")

  #Create Latent Gold script for LC
  filepath_output = paste0(folder,paste0("LC_",model_name,"_output.dat"))
  script = generate_script("LC", ind, cov_ok,cov_problem, N, dat=dat,model_name, filepath_input, filepath_output)
  script_path = paste0(folder,"LC_",model_name,"_script.lgs")
  writeLines(script, script_path)
  
  #Execute Latent Gold script
  shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ',script_path,' /b'))

  #Read model output
  model_output = as.data.frame(fread(filepath_output,dec=","))

  #Rename some columns and add data frame to return list
  setnames(model_output,old=c("Cluster#1","Cluster#2","Cluster#3","Cluster#"),new=c("p1","p2","p3","cluster"))
  to_return = append(to_return,list(model_output))

  #Make sure clusters are assigned the right names
  to_return = fix_cluster_assignment(type="LC",results=to_return)
  
  #Check if no warning was given
  model_lst = paste(readLines(paste0(folder,"LC_",model_name,"_script.lst")), collapse="\n")
  if(grepl("WARNING", model_lst, fixed = TRUE)){
    to_return = append(to_return,list("Error"))
  } else{
    to_return = append(to_return,list("Good"))
  }
  
  return(to_return)
}

# t=perform_lc(9,3,NULL,NULL,1000,1)

```


## Function to perform LCT

@param iteration (int): Iteration number 
@param ind (int): Number of indicators
@param cov_ok (vector): Vector of covariate names (string) that are not problematic (e.g. c("q","z"))
@param cov_problem (vector): Vector of covariate names (string) that are problematic (e.g. c("a","b"))
@param N (int): Size of data set
@param ME (int): Factor representing the degree of measurement error probabilities (1=0.2, 2=0.3, 3=0.5, 4=realistic)
@param folder (string): Folder to save (intermediate) files in

@returns: A list that consists of:
[[1]] Data frame with an overview of model parameters (iteration, ind, cov_ok, cov_problem, N, ME)
[[2]] Data frame with model results

```{r}
perform_lct = function(iteration, ind, cov_ok=NULL, cov_problem=NULL, N, ME, folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\"){

  folder_LC = "F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\LC\\"
  
  #Store model information
  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1,  cov_problem1, N, ME, sep="-")
  to_return = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)
  to_return1 = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)
  
  #Write data set to use to file
  dat = create_subset(iteration, ind ,cov_ok, cov_problem, N, ME)
  dat_name = paste0("LCT_",model_name,"_step1_data.dat")
  
  fwrite(dat,file=paste0(folder,dat_name),sep="\t")

  #Perform LC with 3 classes without problem covariate(s). 
  filepath_output = paste0(folder_LC,paste0("LC_",model_name,"_output.dat"))
  model1 = as.data.frame(fread(filepath_output,dec=","))

  #Rename some columns and add data frame to return list
  setnames(model1,old=c("Cluster#1","Cluster#2","Cluster#3","Cluster#"),new=c("p1","p2","p3","cluster"))
  to_return1 = append(to_return1,list(model1))
  
  #Make sure clusters are assigned the right names
  to_return1 = fix_cluster_assignment(type="LC",results=to_return1)
  
  #Check if no warning was given
  model_lst = paste(readLines(paste0(folder_LC,"LC_",model_name,"_script.lst")), collapse="\n")
  if(grepl("WARNING", model_lst, fixed = TRUE)){
    to_return1 = append(to_return1,list("Error"))
  } else{
    to_return1 = append(to_return1,list("Good"))
  }
  
  model1_output = to_return1[[2]] #Note that 'dat' is not used here, but since the same seed is used, the data set used in perform_lc should be identical.
  
  if(to_return1[[3]]=="Error"){
    to_return = append(to_return,list("Error"))
    to_return = append(to_return,list("Error"))
    return(to_return)
  }
  
  #Combine posterior probabilities for the classes 'permanent' and 'flexible' in the model output
  model1_output$p1 = 1-model1_output$p2 #Note that this is actually p1 + p3, but we call it p1 for the 'generate_script' function to work

  #Write data set to use in second step to file
  dat_name = paste0("LCT_",model_name,"_step1_output.dat")
  
  fwrite(model1_output,file=paste0(folder,dat_name),sep="\t")

  #Create Latent Gold script for second LC model
  filepath_input = paste0(folder,dat_name)
  filepath_output = paste0(folder,"LCT_",model_name,"_step2_output.dat")
  script = generate_script("LCT", ind, cov_ok, cov_problem, N, model_name, dat, filepath_input, filepath_output)
  script_path = paste0(folder,"LCT_",model_name,"_step2_script.lgs")
  writeLines(script, script_path)
   
  #Execute script in Latent Gold and read model output
  shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', script_path, ' /b'))
  model2_output = as.data.frame(fread(filepath_output,dec=","))

  #Combine results from both models to compute final posterior probabilities and fix column names
  all_indicators = c("Y1","Y2","Y3","Y4")
  by_vector = c("id",all_indicators[1:ind],c(cov_ok,cov_problem))
  combined_output = left_join(x=model1_output,y=model2_output,by=by_vector)
  new_names = c("p1.1","p2.1","p2.2","cluster.2","cluster.1")
  setnames(combined_output,old=c("p1.y","Cluster#1","Cluster#2","Cluster#","cluster"),new=new_names)
  combined_output = combined_output[,c(by_vector,new_names)]
  combined_output$p2.2 = fix_number_notation(combined_output$p2.2)
  combined_output$p2.1 = fix_number_notation(combined_output$p2.1)
  
  if(!is.numeric(combined_output$cluster.2)){
    combined_output[combined_output$cluster.2==".",]$cluster.2 = 2
    combined_output$cluster.2 = as.numeric(combined_output$cluster.2)
  }
  
  #Compute posterior probabilities and combine cluster assignments from step 1 and step 2
  combined_output$p1 = combined_output$p2 = combined_output$p3 = combined_output$cluster = NA

  for(i in 1:nrow(combined_output)){
    combined_output[i,]$p2 = 1-as.numeric(combined_output[i,]$p1.1)
    combined_output[i,]$p1 = as.numeric(combined_output[i,]$p1.1)*as.numeric(combined_output[i,]$p2.1)
    combined_output[i,]$p3 = as.numeric(combined_output[i,]$p1.1)*as.numeric(combined_output[i,]$p2.2)

    if(combined_output[i,]$cluster.1==2){
      combined_output[i,]$cluster=2
    } else if((combined_output[i,]$cluster.1==1&combined_output[i,]$cluster.2==1)|(combined_output[i,]$cluster.1==3&combined_output[i,]$cluster.2==1)){
      combined_output[i,]$cluster=1
    } else if((combined_output[i,]$cluster.1==1&combined_output[i,]$cluster.2==2)|(combined_output[i,]$cluster.1==3&combined_output[i,]$cluster.2==2)){
      combined_output[i,]$cluster=3
    }
  }
  
  #Remove redundant columns
  remove_cols = c("cluster.1","cluster.2","p2.1","p2.2","p1.1")
  combined_output = combined_output[,-which(names(combined_output) %in% remove_cols)]
  to_return = append(to_return,list(combined_output))
  
  #Make sure clusters are assigned the right names
  to_return = fix_cluster_assignment(type="LCT",results=to_return)
  
  #Check if no warning was given
  model_lst = paste(readLines(paste0(folder,"LCT_",model_name,"_step2_script.lst")), collapse="\n")
  if(grepl("WARNING", model_lst, fixed = TRUE)){
    to_return = append(to_return,list("Error"))
  } else {
    to_return = append(to_return,list("Good"))
  }
  
  return(to_return)
}

# t1 = perform_lc(1,3,NULL,"SBIgroep",1000,1,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\LC\\")
# t2 = perform_lct(1,3,NULL,"SBIgroep",1000,1)

```


## Function to perform tree-MILC

```{r}
#Function to obtain first round of imputations
impute_value_step1 = function(x){
  return(which(rmultinom(1,1,c(as.numeric(x["p1"])+as.numeric(x["p3"]),as.numeric(x["p2"])))== 1))
}

#Function to obtain second round of imputations 
impute_value_step2 = function(x){
  if(is.na(x["Cluster#1"])){
    return(NA)
  } else {
    return(which(rmultinom(1,1,c(as.numeric(x["Cluster#1"]),as.numeric(x["Cluster#2"])))== 1))
  }
}

perform_treeMILC = function(iteration, ind, cov_ok, cov_problem, N, ME, folder="F:\\Documents\\Thesis\\Simulatie\\Voorbeeld\\"){

  #Store model information
  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1,  cov_problem1, N, ME, sep="-")
  to_return = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)
  
  #Number of bootstrap samples 
  M=5
  dat_org = create_subset(iteration,ind,cov_ok, cov_problem, N,ME)
  dat_org_path = paste0(folder,"tree_MILC_",model_name,"_dat_org.dat")
  fwrite(dat_org,file=dat_org_path,sep="\t")

  #Count combinations of indicators (+covariate) in the original data set
  count_dat = as.data.frame(dat_org[,-which(colnames(dat_org) %in% c("id"))] %>% group_by_all() %>% summarise(COUNT = n()))
  count_dat = count_dat[,-ncol(count_dat)]
  
  #Create help vector to combine results later
  all_indicators = c("Y1","Y2","Y3","Y4")
  by_vector = c(all_indicators[1:ind],cov_ok,cov_problem)

  #Create list to store the results for each bootstrap sample in
  bootstrap_results = list()

  #For each bootstrap sample
  for(i in 1:M){
    dat = dat_org
    set.seed(i) #Set seed to get different bootstrap samples
    sample = dat[sample(1:N,N,replace=TRUE),]
    boot_name = paste0("tree_MILC",model_name,"_boot",i)

    #Perform LC with 3 classes and combine posterior probabilities
    boot_output = perform_lc(iteration,ind,cov_ok,cov_problem,N,ME,dat = sample,folder=folder)

    #If model contains an error, add error to model output
    if(boot_output[[3]]=="Error"){
      to_return = append(to_return,list("Error"))
      to_return = append(to_return,list("Error"))
      return(to_return)
    }
    
    boot_output = boot_output[[2]]

    #Count combinations of indicators (+covariate) in the bootstrap sample
    count_boot = as.data.frame(boot_output[,-which(colnames(boot_output) %in% c("id","cluster"))] 
                          %>% group_by_all() %>% summarise(COUNT = n()))
    count_boot = count_boot[,-ncol(count_boot)]
    
    #If not all combinations are present in the bootstrap sample
    if(nrow(count_boot)!=nrow(count_dat)){
      
      #Get data frame with parameters
      filename_lc = paste0(folder,"LC_",model_name,"_script.lst")
      lc_lst = readChar(filename_lc,file.info(filename_lc)$size)
      lc_lst = strsplit(lc_lst,split="Regression Parameters")
      lc_lst = strsplit(lc_lst[[1]][2],split="Paired Comparisons")
      parameters_path = paste0(folder,"tree_MILC_",model_name,"_boot", i,"_parameters.dat")
      writeLines(lc_lst[[1]][1],parameters_path)
      parameters = suppressWarnings(fread(parameters_path,sep="\t",dec=","))[,1:6]
      names(parameters) = c("term1","term2","term3","term4","term5","coef")
      parameters$coef = as.numeric(parameters$coef)
      remove = which(grepl("Cluster(1)",parameters$term1,fixed=TRUE)|grepl("Y2(1)",parameters$term1,fixed=TRUE)|grepl("Y3(1)",parameters$term1,fixed=TRUE)|grepl("Y4(1)",parameters$term1,fixed=TRUE)|grepl("(1)",parameters$term3,fixed=TRUE)|(grepl("Cluster(1)",parameters$term5,fixed=TRUE)&(grepl("Y1(1)",parameters$term1,fixed=TRUE)))|(grepl("Cluster(2)",parameters$term5,fixed=TRUE)&(grepl("Y1(1)",parameters$term1,fixed=TRUE)))|(grepl("Cluster(3)",parameters$term5,fixed=TRUE)&(grepl("Y1(1)",parameters$term1,fixed=TRUE))))
      parameters = as.data.frame(parameters[-remove,])
      
      #Estimate extra LC model with obtained parameters as starting values
      output_path = paste0(folder,"tree_MILC_",model_name,"_boot", i,"_dat_org_posteriors.dat")
      script = generate_script_treeMILC_step1("LC",ind,cov_ok,cov_problem,model_name,dat=dat,filepath_input=dat_org_path,filepath_output=output_path,parameters)
      script_path = paste0(folder,"tree_MILC_",model_name,"_boot", i,"_dat_org_posteriors.lgs")
      writeLines(script,script_path)
      shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', script_path, ' /b'))
    
      # model_lst = paste(readLines(script_path), collapse="\n")
      # 
      # if(grepl("WARNING", model_lst, fixed = TRUE)){
      #   to_return = append(to_return,list("Error"))
      #   to_return = append(to_return,list("Error"))
      #   return(to_return)
      # }
      #Read model output with posterior probabilities for every observation in the original data set
      dat = as.data.frame(fread(output_path,sep="\t",dec=","))
      setnames(dat,old=c("Cluster#1","Cluster#2","Cluster#3","Cluster#"),new=c("p1","p2","p3","cluster"))
      dat = fix_cluster_assignment(type="LC",list(1,dat))
      dat = dat[[2]]
      dat = dat[,-which(colnames(dat)=="cluster")] 
    } else {
      #If all combinations are present, add posterior probabilities to the observations in the original data set
      dat = left_join(x=dat,y=count_boot,by=by_vector)
    }

    #Sample from obtained posterior membership probabilities
    dat$imp1 = apply(dat,1,impute_value_step1)
    dat$id = as.character(dat$id)
    
    #Create subsets of cases with imputed values of 1 (with original indicator values) and write to file
    subset_ids = dat[dat$imp1==1,]$id
    subset = dat[dat$id %in% subset_ids,]
    filepath_subset = paste0(folder,"tree_MILC",model_name,"_boot", i, "_subset.dat")
    fwrite(subset,file=filepath_subset,sep="\t")

    #Create and execute Latent Gold script for second model
    filepath_output = paste0(folder, boot_name, "_step2_output.dat")
    script = generate_script("treeMILC", ind, cov_ok, cov_problem, N, model_name, subset, filepath_subset, filepath_output)
    script_path = paste0(folder, boot_name, "_step2_script.lgs", sep="")
    writeLines(script, script_path)
    shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', script_path, ' /b'))
    
    #Import model output
    model2_output = as.data.frame(fread(paste0(folder,boot_name,"_step2_output.dat",sep=""),dec=","))

    #Check if no warning was given
    model_lst = paste(readLines(paste0(folder,boot_name,"_step2_script.lst")), collapse="\n")
    if(grepl("WARNING", model_lst, fixed = TRUE)){
      to_return = append(to_return,list("Error"))
      to_return = append(to_return,list("Error"))
      return(to_return)
    }
    
    #Add the results from the second model to the results from the first model
    count_step2 = as.data.frame(model2_output[,-which(colnames(boot_output) %in% c("id","Cluster#"))] 
                          %>% group_by_all() %>% summarise(COUNT = n()))
    count_step2 = count_step2[,-ncol(count_step2)]
    dat = left_join(x=dat,y=count_step2,by=c(all_indicators[1:ind],cov_ok,cov_problem))

    #Sample again from obtained posterior membership probabilities
    dat$imp2 = apply(dat,1,impute_value_step2)
    

    #Combine imputations from both models 
    dat$cluster = dat$imp1
    dat[dat$imp1==1 & ((!is.na(dat$imp2) & dat$imp2 == 1)),]$cluster = 1
    dat[dat$imp1==1 & ((!is.na(dat$imp2) & dat$imp2 == 2)),]$cluster = 3

    #Select and rename columns
    new_names = c("step2_p1","step2_p3")
    setnames(dat,old=c("Cluster#1","Cluster#2"),new=new_names)
    dat = dat[,-which(colnames(dat)=="Cluster#")]
    
    #Fix cluster assignment (if necessary)
    dat = fix_cluster_bootstrap(dat)
    bootstrap_results = append(bootstrap_results,list(dat))
  }
  
  #Add results to final output list
  to_return = append(to_return,list(bootstrap_results))
  to_return = append(to_return,list("Good"))
  return(to_return)
}

# t = perform_treeMILC(1,3,NULL,NULL,1000,1)
# t = perform_treeMILC(1,3,NULL,c("baanduur","SBIgroep"),1000,1)


```


## Function to calculate entropy squared

@param results (list): Results of one particular LC or LCT model

@returns (vector): A vector containing entropy R-squared and entropy

```{r}
get_entropy = function(results){
  
  #For LC and LCT
  if(class(results[[2]])!="list"){ 
    results = results[[2]] #Ignore first data frame with model information
    lc1 = sum((as.numeric(results$p1))*log(as.numeric(results$p1)))
    lc1 = replace(lc1,lc1 =="NaN", 0) #In case some p's are 0
    lc2= sum((results$p2)*log(results$p2))
    lc2 = replace(lc1,lc1 =="NaN", 0)
    lc3 = sum((results$p3)*log(results$p3))
    lc3 = replace(lc1,lc1 =="NaN", 0)
    N=nrow(results)
    entropy = -(lc1+lc2+lc3)
    entropy_squared = 1-(entropy/(N*log(3)))
  }
  
  #For tree-MILC
  else { 
    entropy = entropy_squared = NA
  }
  
  entropy_vector = c(entropy_squared, entropy)
  names(entropy_vector) = c("Entropy R-squared","Entropy")
  
  return(entropy_vector)
}

```


## Function to calculate estimated proportions per cluster 

@param results (list): Results of one particular LC or LCT model

@returns (vector): A vector containing the estimated proportions per cluster

```{r}
get_proportions = function(results){
  #Ignore first data frame with model information
  results = results[[2]]   

  #For LC or LCT: Compute proportions based on posterior probabilities
  if(class(results)!="list"){        
    prop1 = sum(results$p1)
    prop2 = sum(results$p2)
    prop3 = sum(results$p3)
    proportions_vector = c(prop1,prop2,prop3)/nrow(results)
    names(proportions_vector) = 1:3
    return(proportions_vector)
  } 
  
  #For tree-MILC: Compute proportions based on imputations
  else {                    
    
    #Compute proportions per bootstrap
    prop_per_bootstrap = list()
    for(i in 1:length(results)){
      prop_per_bootstrap = append(prop_per_bootstrap,list(summary(factor(results[[i]]$cluster))/nrow(results[[i]])))
    }
  
    #Pool results
    pooled_proportions = colMeans(bind_rows(prop_per_bootstrap))   
    return(pooled_proportions)
  }
}
```


## Helpfunction to compute measurement error matrix for one indicator

@param results (data.frame): Data frame with posterior probabilities
@param ind_vec (vector): Vector containing values for one particular indicator

@returns (matrix): Measurement error matrix for one indicator

```{r}
get_ME_help = function(results,ind_vec){
  
    results$yx = ind_vec
    indicator_matrix = data.frame()
    
    for(i in 1:3){
      indicator_matrix = rbind(indicator_matrix,sum(results[results$yx==i,]$p1))
      indicator_matrix = rbind(indicator_matrix,sum(results[results$yx==i,]$p2))
      indicator_matrix = rbind(indicator_matrix,sum(results[results$yx==i,]$p3))
    }
    
    indicator_matrix = matrix(as.vector(indicator_matrix[,1]),nrow=3,ncol=3,byrow=FALSE)
    indicator_matrix = prop.table(indicator_matrix, margin = 1)
    return(indicator_matrix)
}

```


## Function to compute measurement error matrix for all indicators

@param results (data.frame): Data frame with posterior probabilities
@param ind_vec (vector): Vector containing values for one particular indicator

@returns (matrix): Measurement error matrix for one indicator

```{r}
get_ME = function(results){

  #For LC and LCT: Compute ME for each indicator using the get_ME help function 
  if(class(results[[2]])!="list"){
    results = results[[2]] #Ignore first data frame with model information

    which_ind = results[,colnames(results) %in% c("Y1","Y2","Y3","Y4")]
    to_return = list()
    for(i in 1:ncol(which_ind)){
      to_return = append(to_return,list(get_ME_help(results,which_ind[,i])))
    }
    return(to_return)
  }
  
  #For tree-MILC: Compute ME for each indicator based on classification
  else {
    
    all_indicators = c("Y1","Y2","Y3","Y4")
    num_of_ind = results[[1]]$ind
    results = results[[2]]
    to_return = list()  #Create list that will contain the averages of all bootstrap sample matrices for each indicator 

    for(i in 1:num_of_ind){
      cluster_index = which(names(results[[1]])=="cluster")
      ind_index = which(names(results[[1]])==all_indicators[i])
      summed_matrix = prop.table(table(results[[1]][,cluster_index],results[[1]][,ind_index]),1)
      for(j in 2:length(results)){
        cluster_index = which(names(results[[j]])=="cluster")
        ind_index = which(names(results[[j]])==all_indicators[i])
        summed_matrix = summed_matrix + prop.table(table(results[[j]][,cluster_index],results[[j]][,ind_index]),1)
      }
      
      mean_matrix = summed_matrix / length(results)
      to_return = append(to_return, list(mean_matrix))
    }
    
    return(to_return)
  }
}

```


## ME en heatmap dingetjes

```{r}
#Get one value that represents the difference between the true and estimated amount of measurement error  
get_diff_ME = function(results){
  
  ME = results[[1]]$ME
  ME_results = get_ME(results)
  ME_matrix = get(paste0("ME_matrix",ME))
  matrix = ME_results[[1]]
  
  for(i in 2:length(ME_results)){
    matrix = matrix + ME_results[[i]]
  }
  
  diff_ME = mean(abs((matrix/length(ME_results))-ME_matrix))
  return(diff_ME)
}
```

```{r}
get_diff_ME_diagonal_noabs = function(results){
  
  ME = results[[1]]$ME
  ME_results = get_ME(results)
  ME_matrix = get(paste0("ME_matrix",ME))
  
  if(length(ME_matrix)==2){
    matrix1 = ME_results[[1]]
    if(length(ME_results)>=3){
      matrix1 = matrix1+ME_results[[3]]
    }
    
    matrix2 = ME_results[[2]]
    if(length(ME_results)==4){
      matrix2 = matrix2 + ME_results[[4]]
    }
    
    diff_sum = 0
    
    for(i in 1:3){
      diff_sum = diff_sum + (matrix1[i,i]/ceiling(length(ME_results)/2)-ME_matrix[[1]][i,i])
      diff_sum = diff_sum + (matrix2[i,i]/floor(length(ME_results)/2)-ME_matrix[[2]][i,i])

    }
    
    return(diff_sum/6)
  }
  
  else {
    matrix = ME_results[[1]]
    
    for(i in 2:length(ME_results)){
      matrix = matrix + ME_results[[i]]
    }
    
    diff_diag_1 = ((matrix[1,1]/length(ME_results))-ME_matrix[1,1])
    diff_diag_2 = ((matrix[2,2]/length(ME_results))-ME_matrix[2,2])
    diff_diag_3 = ((matrix[3,3]/length(ME_results))-ME_matrix[3,3])
    
    mean_diff = mean(c(diff_diag_1,diff_diag_2,diff_diag_3))
    return(mean_diff)
  }
}

```

```{r}
# results_template = LC_results[,1:8]

#Get a list of matrices with for every indicator the differences between the input and estimated measurement error matrix
get_diff_matrix = function(results){
  
  ME = results[[1]]$ME
  ind = results[[1]]$ind
  ME_results = get_ME(results)
  ME_matrix = get(paste0("ME_matrix",ME))
  to_return = list()
  
  if(ME!=4){
    for(i in 1:ind){
      to_return = append(to_return,list(abs(ME_results[[i]]-ME_matrix)))
    }
  }
  
  if(ME==4){
      for(i in 1:2){
        if(ME==4){
          to_return = append(to_return,list(abs(ME_results[[i]]-ME_matrix[[i]])))  
        }
      }
          
      #Add first
      if((ME==4) & (ind>2)){
        to_return = append(to_return,list(abs(ME_results[[3]]-ME_matrix[[1]])))
      }
      if ((ME==4) & (ind>3)){
        to_return = append(to_return,list(abs(ME_results[[4]]-ME_matrix[[2]])))
      }
  }
  return(to_return)
}


#Get a list of a list of matrices and return a list with the mean matrix of every sublist
get_mean_matrix = function(list){
  num_matrices = length(list)
  num_ind = length(list[[1]])
  
  to_return = list()
  for(i in 1:num_ind){
    temp_matrix = list[[1]][[i]]
    for(j in 2:num_matrices){
      temp_matrix = temp_matrix + list[[j]][[i]]
    }
    temp_matrix = temp_matrix/num_matrices
    to_return=append(to_return,list(temp_matrix))
  }
  return(to_return)
}
```

```{r}
#(Mean) bias
j=1000
cov=c("null","baanduur","baanduur-SBIgroep")

#Heatmaps bias (10%, 20%, 30% measurement error)
for(r in "null"){
  for(k in 3){
    if(k==2){c="q"} else{c="null"}
    heatmap=get_ME_heatmap(1,k,c,r,j)
    name = paste(k,c,r,j,sep="-")
    filename = paste0("F:/Documents/Thesis/Schrijfbestanden/Plot_Sim_8/Met_Haakjes/Heatmap_",name,"_Bias_123.pdf")
    ggsave(plot = heatmap, width=3.9,height=3,dpi = 300, filename = filename)
  }
}

#Heatmaps variance (10%, 20%, 30% measurement error)
for(r in "null"){
  for(k in 3){
    if(k==2){c="q"} else{c="null"}
    heatmap=get_ME_heatmap(2,k,c,r,j)
    name = paste(k,c,r,j,sep="-")
    filename = paste0("F:/Documents/Thesis/Schrijfbestanden/Plot_Sim_8/Met_Haakjes/Heatmap_",name,"_Variance_123.pdf")
    ggsave(plot = heatmap, width=3.9,height=3,dpi = 300, filename = filename)
  }
}

j=10000
#Heatmaps bias (realistic measurement error)
for(r in cov){
  c="q"
  k=2
  heatmap=get_ME_heatmap_realistic(1,2,"q",r,j)
  name = paste(k,c,r,j,sep="-")
  filename = paste0("F:/Documents/Thesis/Schrijfbestanden/Plot_Sim_1/Bias/Heatmap_",name,"_Bias_4.pdf")
  ggsave(heatmap, width=3.4,height=3,dpi = 300, filename = filename)
}

#Heatmaps variance (realistic measurement error)
for(r in cov){
  c="q"
  k=2
  heatmap=get_ME_heatmap_realistic(2,2,"q",r,j)
  name = paste(k,c,r,j,sep="-")
  filename = paste0("F:/Documents/Thesis/Schrijfbestanden/Plot_Sim_1/Bias/Heatmap_",name,"_Variance_4.pdf")
  ggsave(heatmap, width=3.4,height=3,dpi = 300, filename = filename)
}
```


```{r}
#Get a list of matrices with for every indicator the variances of the measurement error probability matrix
get_var_ME = function(models,ind,cov_ok,cov_problem,N,ME,ind_type=NULL){

    if(ME==4){
      select_inds = seq(ind_type,ind,2)
    } else {
      select_inds = 1:ind
    }
    
    #Get list of measurement error probability matrices for all iterations of a certain condition
    ME_list = list()

    for(i in 1:length(models)){
     if((models[[i]][[1]]$ind == ind) & (models[[i]][[1]]$cov_ok == cov_ok) & (models[[i]][[1]]$cov_problem == cov_problem) & (models[[i]][[1]]$N == N) & (models[[i]][[1]]$ME == ME)){ 
        ME_list = append(ME_list, list(get_ME(models[[i]])))
      }     
    }

  to_return = list()
  
  #For every indicator
  for(i in select_inds){
    
    var_vec = vector()
    
    for(m in 1:3){
      for(n in 1:3){
        
        vec = vector()
        
        for(o in 1:length(ME_list)){
          vec = c(vec,ME_list[[o]][[i]][m,n])
        }
        
        var_vec = c(var_vec,var(vec))
      }
    }
    
    temp_matrix = matrix(var_vec,ncol=3,byrow=TRUE)
    to_return = append(to_return,list(temp_matrix))
  }
  
  return(to_return)
}
```

```{R}
#Create a single heatmap for one partiular indicator
get_ME_heatmap = function(type,ind,cov_ok,cov_problem,N){
  
  results_template = LC_results[,1:8]
  results_template$ME = as.factor(results_template$ME)
  levels(results_template$ME)[1] = "10%"
  levels(results_template$ME)[2] = "20%"
  levels(results_template$ME)[3] = "30%"
  levels(results_template$ME)[4] = "Realistic 7%"

  df_to_plot = data.frame()
  
  for(k in levels(results_template$ME)[1:3]){
    indexes = as.numeric(row.names(results_template[(results_template$ind == ind) & (results_template$cov_ok == cov_ok) & (results_template$cov_problem == cov_problem) &  (results_template$N == N) & (results_template$ME == k) ,]))
    LC_diff_list = LCT_diff_list = treeMILC_diff_list = list()
    N = as.numeric(N)
    if(type==1){
      for(i in indexes){
        LC_diff_list = append(LC_diff_list,list(get_diff_matrix(LC_models[[i]])))
        LCT_diff_list = append(LCT_diff_list,list(get_diff_matrix(LCT_models[[i]])))
        treeMILC_diff_list = append(treeMILC_diff_list,list(get_diff_matrix(treeMILC_models[[i]]))) 
      }     
      LC_mean_diff = get_mean_matrix(LC_diff_list)
      LCT_mean_diff = get_mean_matrix(LCT_diff_list)
      treeMILC_mean_diff = get_mean_matrix(treeMILC_diff_list)

    } else if(type==2){
        LC_mean_diff = get_var_ME(LC_models,ind,cov_ok,cov_problem,N,which(levels(results_template$ME)==k))
        LCT_mean_diff = get_var_ME(LCT_models,ind,cov_ok,cov_problem,N,which(levels(results_template$ME)==k))
        treeMILC_mean_diff = get_var_ME(treeMILC_models,ind,cov_ok,cov_problem,N,which(levels(results_template$ME)==k)) 
    }

    LC_df_to_plot = as.matrix(LC_mean_diff[[1]])
    LCT_df_to_plot = as.matrix(LCT_mean_diff[[1]])
    treeMILC_df_to_plot = as.matrix(treeMILC_mean_diff[[1]])

    for(i in 2:ind){
      LC_df_to_plot = LC_df_to_plot + as.matrix(LC_mean_diff[[i]])
      LCT_df_to_plot = LCT_df_to_plot + as.matrix(LCT_mean_diff[[i]])
      treeMILC_df_to_plot = treeMILC_df_to_plot + as.matrix(treeMILC_mean_diff[[i]])
    }
    return(as.table(LC_df_to_plot/ind))
    LC_df_to_plot = as.data.frame(as.table(LC_df_to_plot/ind))
    LC_df_to_plot$type = "LC"
    LCT_df_to_plot = as.data.frame(as.table(LCT_df_to_plot/ind))
    LCT_df_to_plot$type = "LCT"
    treeMILC_df_to_plot = as.data.frame(as.table(treeMILC_df_to_plot/ind))
    treeMILC_df_to_plot$type = "tree-MILC"
    temp = rbind(LC_df_to_plot,LCT_df_to_plot,treeMILC_df_to_plot)
    temp$ME = k
    colnames(temp) = c("Model","Indicator","Bias","type","ME")
    df_to_plot = rbind(df_to_plot,temp)
    colnames(df_to_plot) = c("Model","Indicator","Bias","type","ME")
    
    df_to_plot$Model = as.character(df_to_plot$Model)
    df_to_plot$Indicator = as.character(df_to_plot$Indicator)

    df_to_plot[df_to_plot$Model=="A"|df_to_plot$Model=="1",]$Model = "P"
    df_to_plot[df_to_plot$Model=="B"|df_to_plot$Model=="2",]$Model = "O"
    df_to_plot[df_to_plot$Model=="C"|df_to_plot$Model=="3",]$Model = "F"
    df_to_plot[df_to_plot$Indicator=="A"|df_to_plot$Indicator=="1",]$Indicator = "P"
    df_to_plot[df_to_plot$Indicator=="B"|df_to_plot$Indicator=="2",]$Indicator = "O"
    df_to_plot[df_to_plot$Indicator=="C"|df_to_plot$Indicator=="3",]$Indicator = "F"
    
    df_to_plot$Model <- factor(df_to_plot$Model, levels = c("O", "F", "P"))
    df_to_plot$Indicator <- factor(df_to_plot$Indicator, levels = c("P", "F", "O"))
    
  }
  
  if(type==1){
        df_to_plot[df_to_plot$Model=="P"&df_to_plot$Indicator=="P",]$Bias =-df_to_plot[df_to_plot$Model=="P"&df_to_plot$Indicator=="P",]$Bias
    df_to_plot[df_to_plot$Model=="O"&df_to_plot$Indicator=="O",]$Bias =-df_to_plot[df_to_plot$Model=="O"&df_to_plot$Indicator=="O",]$Bias
    df_to_plot[df_to_plot$Model=="F"&df_to_plot$Indicator=="F",]$Bias =-df_to_plot[df_to_plot$Model=="F"&df_to_plot$Indicator=="F",]$Bias
    

    max_abs = max(abs(df_to_plot$Bias))
    rng = c(-max_abs,max_abs)

    cc = rev(brewer.pal(9,"RdBu"))
    g = ggplot(df_to_plot, aes(Indicator,Model))  + geom_tile(aes(fill=Bias))+  scale_fill_gradientn(colors=rev(brewer.pal(9,"RdBu")),values=rescale(c(rng[1],0,rng[2])),limits=c(rng[1],rng[2])) + facet_grid(rows = vars(type),cols=vars(ME),labeller=labeller(.rows = label_value, .cols = label_both)) + 
  labs(fill="(Mean) Bias")

  } else { 
    
    rng = c(min(df_to_plot$Bias),max(df_to_plot$Bias))
    df_to_plot$Variance=df_to_plot$Bias
    g = ggplot(df_to_plot, aes(Indicator,Model))  + geom_tile(aes(fill=Variance))   +  scale_fill_gradientn(colors=brewer.pal(9,"Reds"),values=rescale(c(0,rng[2])),limits=c(0,rng[2])) + facet_grid(rows = vars(type),cols=vars(ME),labeller=labeller(.rows = label_value, .cols = label_both))  + 
  labs(fill="(Mean) Variance")
  }

    return(g)
}

 # t=get_ME_heatmap(2,2, "q","baanduur",10000)
 
```

```{r}
get_ME_heatmap_realistic = function(type,ind,cov_ok,cov_problem,N){
  
  results_template = LC_results_10000[,1:7]
  
  df_to_plot = data.frame()
    
  indexes = as.numeric(row.names(results_template[(results_template$ind == ind) & (results_template$cov_ok == cov_ok) & (results_template$cov_problem == cov_problem) & (results_template$N == N) & (results_template$ME == 4) ,]))
  N = as.numeric(N)
    
    for(k in 1:2){
      LC_diff_list = LCT_diff_list = treeMILC_diff_list = list()
    if(type==1){
       for(i in indexes){
          LC_diff_list = append(LC_diff_list,list(get_diff_matrix(LC_models_10000[[i]])[seq(k,ind,2)]))
          LCT_diff_list = append(LCT_diff_list,list(get_diff_matrix(LCT_models_10000[[i]])[seq(k,ind,2)]))
          treeMILC_diff_list = append(treeMILC_diff_list,list(get_diff_matrix(treeMILC_models_10000[[i]])[seq(k,ind,2)])) 
       }
        LC_mean_diff = get_mean_matrix(LC_diff_list)
        LCT_mean_diff = get_mean_matrix(LCT_diff_list)
        treeMILC_mean_diff = get_mean_matrix(treeMILC_diff_list)
        
    } else if(type==2){
        LC_mean_diff = get_var_ME(LC_models_10000,ind,cov_ok,cov_problem,ME=4,N,k)
        LCT_mean_diff = get_var_ME(LCT_models_10000,ind,cov_ok,cov_problem,N,ME=4,k)
        treeMILC_mean_diff = get_var_ME(treeMILC_models_10000,ind,cov_ok,cov_problem,N,ME=4,k) 
    }
      
     if(length(seq(k,ind,2))==1){
            LC_df_to_plot = as.data.frame(matrix(unlist(LC_mean_diff), ncol = 3, byrow = FALSE))     
            LCT_df_to_plot = as.data.frame(matrix(unlist(LCT_mean_diff), ncol = 3, byrow = FALSE))          
            treeMILC_df_to_plot = as.data.frame(matrix(unlist(treeMILC_mean_diff), ncol = 3, byrow = FALSE))          

      } else {
            LC_df_to_plot = get_mean_matrix(LC_mean_diff)
            LC_df_to_plot = as.data.frame(matrix(unlist(LC_df_to_plot), ncol = 3, byrow = FALSE))
            LCT_df_to_plot = get_mean_matrix(LCT_mean_diff)
            LCT_df_to_plot = as.data.frame(matrix(unlist(LCT_df_to_plot), ncol = 3, byrow = FALSE))
            treeMILC_df_to_plot = get_mean_matrix(treeMILC_mean_diff)
            treeMILC_df_to_plot = as.data.frame(matrix(unlist(treeMILC_df_to_plot), ncol = 3, byrow = FALSE))
      }
      

        LC_df_to_plot$Model = rownames(LC_df_to_plot)
        LC_df_to_plot <- melt(setDT(LC_df_to_plot), id.vars = c("Model"), variable.name = "Indicator")
        LCT_df_to_plot$Model = rownames(LCT_df_to_plot)
        LCT_df_to_plot <- melt(setDT(LCT_df_to_plot), id.vars = c("Model"), variable.name = "Indicator")
        treeMILC_df_to_plot$Model = rownames(treeMILC_df_to_plot)
        treeMILC_df_to_plot <- melt(setDT(treeMILC_df_to_plot), id.vars = c("Model"), variable.name = "Indicator")

        LC_df_to_plot$type = "LC"
        LCT_df_to_plot$type = "LCT"
        treeMILC_df_to_plot$type = "tree-MILC"
        temp = rbind(LC_df_to_plot,LCT_df_to_plot,treeMILC_df_to_plot)
        temp$indicator = ifelse(k==1,"Ind. 1","Ind. 2")
        colnames(temp) = c("Model","Indicator","Bias","type","ME")
    
        df_to_plot = rbind(df_to_plot,temp)
    }
        colnames(df_to_plot) = c("Model","Indicator","Bias","type","ME")
        df_to_plot$Model = as.character(df_to_plot$Model)
        df_to_plot$Indicator = as.character(df_to_plot$Indicator)
        df_to_plot[df_to_plot$Model=="V1"|df_to_plot$Model=="1",]$Model = "P"
        df_to_plot[df_to_plot$Model=="V2"|df_to_plot$Model=="2",]$Model = "O"
        df_to_plot[df_to_plot$Model=="V3"|df_to_plot$Model=="3",]$Model = "F"
        df_to_plot[df_to_plot$Indicator=="V1"|df_to_plot$Indicator=="1",]$Indicator = "P"
        df_to_plot[df_to_plot$Indicator=="V2"|df_to_plot$Indicator=="2",]$Indicator = "O"
        df_to_plot[df_to_plot$Indicator=="V3"|df_to_plot$Indicator=="3",]$Indicator = "F"

        df_to_plot$Model <- factor(df_to_plot$Model, levels = c("O", "F", "P"))
        df_to_plot$Indicator <- factor(df_to_plot$Indicator, levels = c("P", "F", "O"))
        
        df_to_plot$ME = as.factor(df_to_plot$ME)
        df_to_plot$Variance = df_to_plot$Bias

      if(type==1){
        
       df_to_plot[df_to_plot$Model=="P"&df_to_plot$Indicator=="P",]$Bias =-df_to_plot[df_to_plot$Model=="P"&df_to_plot$Indicator=="P",]$Bias 
    df_to_plot[df_to_plot$Model=="O"&df_to_plot$Indicator=="O",]$Bias =-df_to_plot[df_to_plot$Model=="O"&df_to_plot$Indicator=="O",]$Bias 
    df_to_plot[df_to_plot$Model=="F"&df_to_plot$Indicator=="F",]$Bias =-df_to_plot[df_to_plot$Model=="F"&df_to_plot$Indicator=="F",]$Bias 
    
    max_abs = max(abs(df_to_plot$Bias))
    rng = c(-max_abs,max_abs)
      g = ggplot(df_to_plot, aes(Indicator,Model))  + geom_tile(aes(fill=Bias)) +  scale_fill_gradientn(colors=rev(brewer.pal(9,"RdBu")),values=rescale(c(rng[1],0,rng[2])),limits=c(rng[1],rng[2])) + facet_grid(rows = vars(type),cols=vars(ME),labeller=labeller(.rows = label_value, .cols = label_value))  + 
  labs(fill="Bias")#facet_wrap(~ type)}
      
      } else if(type==2){
      
        rng = c(min(df_to_plot$Variance),max(df_to_plot$Variance))

      g = ggplot(df_to_plot, aes(Indicator,Model))  + geom_tile(aes(fill=Variance)) +  scale_fill_gradientn(colors=brewer.pal(9,"Reds"),values=rescale(c(0,rng[2])),limits=c(0,rng[2])) + facet_grid(rows = vars(type),cols=vars(ME),labeller=labeller(.rows = label_value, .cols = label_value))  + 
  labs(fill="Variance")#facet_wrap(~ type)}
      }

    return(g)
  }

# t1=get_ME_heatmap_realistic(1,2,1,1000)
# t2=get_ME_heatmap_realistic(2,2,1,1000)

# grid.arrange(t1,t2,ncol=2)

# t=get_ME_heatmap_realistic(2,3,"null","baanduur",1000)


```


## Perform LC, LCT and  tree-MILC analyis for all simulation conditions

```{r eval = FALSE}
ind = c(2,3)
N = c(10000)
ME = c(1:4)
iteration = c(49:50)
cov_problem = c("NULL","baanduur","baanduur-SBIgroep")

#Create data frame for all combinations
results_template = data.frame()
for(i in ind){
  if(i==2){
    cov_ok="q"
  } else{
    cov_ok="NULL"
  }

  for(j in N){
    for(k in ME){
      for(l in iteration){
        for(m in cov_problem){
          name = paste(i,cov_ok,m,j,k,sep="-")
          row=c(l,i,cov_ok,m,j,k,name)
          results_template=rbind(results_template,row)
        }
      }
    }
  }
}

colnames(results_template) = c("iteration","indicator","cov_ok","cov_problem","N","ME","id")

m = 1152
errors = 0
error_vec = vector()

#Execute all LC models
LC_models_10000 = list()
LCT_models_10000 = list()
treeMILC_models_10000 = list()

for(l in iteration){
  for(k in ME){
    for(i in ind){
      if(i==2){
        cov_ok = "q"
      } else {
        cov_ok = NULL
      }

      for(j in N){
        for(n in cov_problem){
          m = m + 1
          name = paste0(i,"-",ifelse(is.null(cov_ok),"NULL",cov_ok),"-",n,"-",j,"-",k)
          print(paste0("--------------", m ,"---------------"))
  
          name2 = paste(l,i,ifelse(is.null(cov_ok),"NULL",cov_ok),n,j,k,sep="-")
          row=c(l,i,ifelse(is.null(cov_ok),"NULL",cov_ok),n,j,k,name2)
          results_template=rbind(results_template,row)
        
          if(n=="NULL"){
            n=NULL
          } else if(n=="baanduur-SBIgroep"){
            n=c("baanduur","SBIgroep")
          }

          LC = perform_lc(l,i,cov_ok,n,j,k,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\LC\\")
          LC_models_10000 = append(LC_models_10000,list(LC))
          print(paste0("LC model ",name," complete."))

          LCT = perform_lct(l,i,cov_ok,n,j,k,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\LCT\\")
          LCT_models_10000 = append(LCT_models_10000,list(LCT))
          print(paste0("LCT model ",name," complete."))

          treeMILC = perform_treeMILC(l,i,cov_ok,n,j,k,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\treeMILC_10000\\")
          treeMILC_models_10000  = append(treeMILC_models_10000 ,list(treeMILC))

          # (LC[[3]]=="Error")|(LCT[[3]]=="Error")|
          if((treeMILC[[3]]=="Error")){
            errors = errors + 1
            error_vec = c(error_vec,LC[[1]]$id)
          }
          print(paste0("treeMILC model ",name," complete."))

          print(paste0("Number of errors caught: ",errors, " in ",error_vec))
        }
      }
    }
    
    #If a certain data set does not exist, create it
    if(exists(paste0("simDat",k,"_iteration",l))){
      rm(list=paste0("simDat",k,"_iteration",l))
    }
  }
}

```

```{r}
b = 2
m = 1

for(i in b:nrow(results_template)){
  z = (results_template[i,])
    m = m + 1
    name = paste0(results_template[i,]$indicator,"-",results_template[i,]$cov_ok,"-",results_template[i,]$cov_problem,"-",results_template[i,]$N,"-",results_template[i,]$ME)
    print(paste0("--------------", m ,"---------------"))
  
    if(results_template[i,]$cov_problem=="NULL"){
      n=NULL
    } else if(results_template[i,]$cov_problem=="baanduur-SBIgroep"){
      n=c("baanduur","SBIgroep")
    } else if(results_template[i,]$cov_problem=="SBIgroep"){
      n="SBIgroep"
    } else if(results_template[i,]$cov_problem=="baanduur"){
      n="baanduur"
    }
    
    if(results_template[i,]$cov_ok=="NULL"){
      cov_ok=NULL
    } else {
      cov_ok=results_template[i,]$cov_ok
    }

    if(i>458){
     LC = perform_lc(results_template[i,]$iteration,results_template[i,]$indicator,cov_ok,n,results_template[i,]$N,results_template[i,]$ME,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\LC\\")
    LC_models = append(LC_models,list(LC))
    print(paste0("LC model ",name," complete."))
  
    LCT = perform_lct(results_template[i,]$iteration,results_template[i,]$indicator,cov_ok,n,results_template[i,]$N,results_template[i,]$ME,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\LCT\\")
    LCT_models = append(LCT_models,list(LCT))
    print(paste0("LCT model ",name," complete."))
    }
  
    treeMILC = perform_treeMILC(results_template[i,]$iteration,results_template[i,]$indicator,cov_ok,n,results_template[i,]$N,results_template[i,]$ME,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_8_met_twee_cov\\treeMILC\\")
    treeMILC_models = append(treeMILC_models,list(treeMILC))
    print(paste0("treeMILC model ",name," complete."))

    if((LC[[3]]=="Error")|(LCT[[3]]=="Error")|(treeMILC[[3]]=="Error")){
      errors = errors + 1
      error_vec = c(error_vec,LC[[1]]$id)
    }

    print(paste0("Number of errors caught: ",errors, " in ",error_vec))
    
    # If a certain data set does not exist, create it
    if(exists(paste0("simDat",results_template[i,]$ME,"_iteration",results_template[i,]$iteration))){
      rm(list=paste0("simDat",results_template[i,]$ME,"_iteration",results_template[i,]$iteration))
   }

}

```

