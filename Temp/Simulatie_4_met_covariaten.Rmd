---
title: "Simulatie"
output: html_document
date: '2023-02-24'
---

## Initializations

```{r eval = FALSE}
library(stringr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(data.table)
library(ExPosition)
library(gridExtra)
library(gdata)

t=treeMILC_models2[[26]][[2]][[5]]
t[t$cluster==3,]

  for(i in 1:300){
      if(treeMILC_models2[[i]][[1]]$ind==2&treeMILC_models2[[i]][[1]]$cov_problem=="baanduur"&treeMILC_models2[[i]][[1]]$N==1000&treeMILC_models2[[i]][[1]]$ME==3){
      print(i)
      }
  }

for(i in 1:5){
    print(summary(factor(treeMILC_models3[[254]][[2]][[i]]$cluster)))
}

for(i in 1:5){
  print(table(treeMILC_models3[[254]][[2]][[i]]$cluster,treeMILC_models3[[254]][[2]][[i]]$Y1))
}


plot_df = df[df$Contract=="Permanent",]
g = plot_df %>% ggplot( aes(x=indicator, y=prop, fill=type)) + geom_bar(stat='identity', position='dodge')  + scale_fill_manual(name="Model",values=group.colors)
g = g + labs(y= "Population proportion estimates", x = "Number of indicators") 
g = g + facet_grid(cov_problem ~  ME,labeller=label_value) + geom_hline(aes(yintercept=hline), color = "black",size=0.3)
p5 = g + geom_errorbar(aes(ymin=prop-sd, ymax=prop+sd), width=.25, size=0.3, position=position_dodge(.9))
p5

load("Y:/Combineren/Projecten/Stage_Elisca/RData/Simulatie_4_met_covariaten.RData")
load("F:/Documents/Thesis/Simulatie/Simulatie_4_met_covariaten/Simulatie_4_met_covariaten.RData")
save.image("F:/Documents/Thesis/Simulatie/Simulatie_4_met_covariaten/Simulatie_4_met_covariaten.RData")
```


## True proportions in simulated data

```{r eval = FALSE}
true_proportions = c(0.6110, 0.2568, 0.1322)
names(true_proportions) = c("Vast","Overig","Flex")
```


## Function to create a matrix with the (real) measurement error probabilities used to simulate data

```{r}
create_real_ME_matrix = function(a2,a3,b22,b33,b23,b32){
  row1 = c(1/(1+exp(a2)+exp(a3)),exp(a2)/(1+exp(a2)+exp(a3)),exp(a3)/(1+exp(a2)+exp(a3)))
  row2 = c(1/(1+exp(a2+b22)+exp(a3+b32)),exp(a2+b22)/(1+exp(a2+b22)+exp(a3+b32)),exp(a3+b32)/(1+exp(a2+b22)+exp(a3+b32)))
  row3 = c(1/(1+exp(a2+b23)+exp(a3+b33)),exp(a2+b23)/(1+exp(a2+b23)+exp(a3+b33)),exp(a3+b33)/(1+exp(a2+b23)+exp(a3+b33)))
  matrix = matrix(c(row1,row2,row3),nrow=3,ncol=3,byrow=TRUE)
  return(matrix)
}
```


## Function to generate a data set

@param seed (int): Seed for generating a data set
@param ME (int): Factor representing the degree of measurement error (1=0.1, 2=0.2, 3=0.3, 4=realistic)
@param folder (string): Folder to save files in

@returns (data.frame): A simulated data set of size N=10,000 with the indicated degree of measurement error

```{r}
simulate_data = function(seed, ME, folder="F:\\Documents\\Thesis\\Simulatie\\Voorbeeld\\"){
  
  #Create Latent Gold script for LC
  filepath_input = paste0(folder,"exampleData.dat")

  #Write exampleData.dat to file
  exampleData = paste0("id Y1 Y2 Y3 Y4 q a w
1  1 1 1 1 1 1 315
2  2 2 2 2 1 2 5
3  3 3 3 3 1 3 10
4  1 1 1 1 1 4 3
5  2 2 2 2 1 5 10
6  3 3 3 3 1 6 20
7  1 1 1 1 1 7 20
8  2 2 2 2 1 8 50
9  3 3 3 3 1 9 20
10 1 1 1 1 2 1 250
11 2 2 2 2 2 2 2
12 3 3 3 3 2 3 20
13 1 1 1 1 2 4 25
14 2 2 2 2 2 5 10
15 3 3 3 3 2 6 10
16 1 1 1 1 2 7 20
17 2 2 2 2 2 8 100
18 3 3 3 3 2 9 110
")
  writeLines(exampleData, filepath_input)
  
  #Create Latent GOLD script to simulate data
  filepath_input = paste0(folder,"exampleData.dat")
  
  script_part1 = paste0("version = 6.0\ninfile '",filepath_input,"' \n\nmodel
    title 'simulation",ME,"';
    options
    algorithm
        tolerance=1e-08 emtolerance=0.01 emiteration=500 nriterations=500;
    startvalues
        seed=1 sets=100 tolerance=1e-05 iterations=100;
    montecarlo
        seed=1 replicates=500 tolerance=1e-008;
    bayes
        categorical=1 variances=1 latent=1 poisson=1;
    missing includeall;
    output       
    	parameters=first standarderrors profile reorderclasses iterationdetails;\n")

  #Parameter estimates with contract, geslacht, SBIgroep
  contract = c(-0.5470, -2.0483)
  q = c(0.9282, 0.3358) #geslacht
  a = c(-2.0163, -0.0142, -3.9474, 0.4709, -4.2761, -0.9495, -3.3867, 1.4923, -1.4400, -0.8672, -2.7104, 3.8292, -6.2280, -0.2571, -5.1271, 0.1029) #SBIgroep

  #Parameter estimates with contract, geslacht, baanduurklasse en grootteklasse
  # contract = c(5.0912, 2.2586)
  # geslacht = c(-0.4393, 0.1336)
  # baanduurklasse = c(-7.7567, -0.5257, -8.0441, -0.9838, -8.6775, -2.2208, -9.3091, -3.6033, -9.1635, -5.7043)
  # grootteklasse = c(-3.0451, 0.3655, 3.0037, 1.0919)
  
  #Parameter estimates with all covariates
  # contract = c(4.5785, 2.4205)
  # A = c(-0.4813, 0.6864, 3.0274, 1.1838)
  # B = c(-4.7575, -0.2295, -5.2183, -0.8380, -4.0882, -1.0176)
  # C = c(-5.3296, -0.3249, -5.3004, -0.7125, -5.9374, -2.0372, -6.4652, -3.7468, -5.7428, -5.7281)
  # D = c(0.057, 0.0264, -1.6257, 1.0792, -1.0678, 0.2914, -2.2507, 1.7213, 1.6635, -0.3539, 0.1271, 4.5415, -2.4706, 0.7905, -1.8779, 0.9115)
  # E = c(1.6141, -0.5124, 1.3022, 2.6495, 1.6152, 1.8783, -0.0513, 1.5179)
  # FF = c(-0.0037, -0.1063, 0.6321, -0.1844, -0.0181, -0.1373)
  # Q = c(-0.9928, -0.0376)
  
  data_param = gsub(",","",toString(c(contract,q,a)))

  #Parameters for 10% measurement error
  if(ME==1){
    outfile_name = paste0("simDat1_iteration",seed,".dat")
    a2=a3=-log(18)  #Coefficients for measurement error matrix
    b22=b33=log(324)
    b32=b23=log(18)
    ME_matrix1 = create_real_ME_matrix(a2,a3,b22,b33,b23,b32)
    ME_coefs = c(a2,a3,b22,b32,b23,b33,"\n")
    ME_coefs = gsub(",","",toString(rep(ME_coefs,4)))
    parameters = paste("\n",data_param,"\n",ME_coefs,"}\nend model")
  }

  #Parameters for 20% measurement error
  else if(ME==2){
    outfile_name = paste0("simDat2_iteration",seed,".dat")
    a2=a3=-3*log(2) #Coefficients for measurement error matrix
    b22=b33=6*log(2)
    b32=b23=3*log(2)
    ME_matrix2 = create_real_ME_matrix(a2,a3,b22,b33,b23,b32)
    ME_coefs = c(a2,a3,b22,b32,b23,b33,"\n")
    ME_coefs = gsub(",","",toString(rep(ME_coefs,4)))
    parameters = paste("\n",data_param,"\n",ME_coefs,"}\nend model")
  }
  
  #Parameters for 30% measurement error
  else if(ME==3){
    outfile_name = paste0("simDat3_iteration",seed,".dat")
    a2=a3=-1.54045 #Coefficients for measurement error matrix
    b22=b33=3.0809
    b32=b23=1.54045
    ME_matrix3 = create_real_ME_matrix(a2,a3,b22,b33,b23,b32)
    ME_coefs = c(a2,a3,b22,b32,b23,b33,"\n")
    ME_coefs = gsub(",","",toString(rep(ME_coefs,4)))
    parameters = paste("\n",data_param,"\n",ME_coefs,"}\nend model")
  }

  #Parameters for realistic amount of measurement error
  else if(ME==4){
    outfile_name = paste0("simDat4_iteration",seed,".dat")
    Y1_a2=-4.94368 #Coefficients for indicator 1
    Y1_a3=-4.4917
    Y1_b22=5.667
    Y1_b32=3.099
    Y1_b23=4.5506
    Y1_b33=7.64123
    Y2_a2=-2.63157 #Coefficients for indicator 2
    Y2_a3=-6.14311
    Y2_b22=5.03275
    Y2_b32=1.72427
    Y2_b23=1.395
    Y2_b33=11.92
    
    #Save 'real' ME_matrix4 in the global environment for later (i.e. if a certain 'real' matrix does not yet exist, create it)
    if(!exists(paste0("ME_matrix",ME))){
      assign(paste0("ME_matrix",4,"a"),create_ME_matrix(Y1_a2,Y1_a3,Y1_b22,Y1_b33,Y1_b23,Y1_b32),envir=globalenv())
      assign(paste0("ME_matrix",4,"b"),create_ME_matrix(Y2_a2,Y2_a3,Y2_b22,Y2_b33,Y2_b23,Y2_b32),envir=globalenv())
      assign(paste0("ME_matrix",4),list(ME_matrix4a,ME_matrix4b),envir=globalenv())
    }
    
    ME_coefs_Y1 = c(Y1_a2,Y1_a3,Y1_b22,Y1_b32,Y1_b23,Y1_b33,"\n")
    ME_coefs_Y2 = c(Y2_a2,Y2_a3,Y2_b22,Y2_b32,Y2_b23,Y2_b33,"\n")
    ME_coefs = gsub(",","",toString(rep(c(ME_coefs_Y1,ME_coefs_Y2),2))) 
    parameters = paste(data_param,"\n",ME_coefs,"}\nend model")
  }
  
  #Save 'real' matrix in the global environment for later (i.e. if a certain 'real' matrix does not yet exist, create it)
  if(!exists(paste0("ME_matrix",ME))){
    assign(paste0("ME_matrix",ME),create_real_ME_matrix(a2,a3,b22,b33,b23,b32),envir=globalenv())
  }
  
  script_part2 = paste0("\toutfile '",outfile_name, "' simulation=1 seed=",seed,";
    variables
         caseid id;
         caseweight w;
         dependent Y1 nominal 3, Y2 nominal 3, Y3 nominal 3, Y4 nominal 3;
         independent q nominal, a nominal;
         latent cluster nominal 3;
     equations
         cluster <- 1 + q + a;			
         Y1      <- 1 + cluster;	
         Y2      <- 1 + cluster;
         Y3      <- 1 + cluster;
         Y4      <- 1 + cluster;
{ ")
  
  #Combine parts of script
  script = paste0(script_part1,script_part2,parameters)
  writeLines(script, paste0(folder,"simDat",ME,"_iteration",seed,"_script.lgs"))
  
  #Execute Latent Gold script
  shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', folder, paste0("simDat",ME,"_iteration",seed,"_script.lgs"), ' /b'))

  #Import simulated data set
  simDat = read.delim(outfile_name,sep="\t",dec=",")
  
  #Add extra 'problem' covariate category
  # simDat = add_extra_covcat(simDat,which(names(simDat)=="a"))

  return(simDat)
}

data = simulate_data(1, 1, folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_4_met_covariaten\\")

# write.table(x=data, file = "F:/Documents/Thesis/Simulatie/Simulatie_8_met_twee_cov/simDat_SBIgroep.dat", row.names=FALSE, quote=FALSE)


```


## Function to adjust simulated covariates

@param data (data.frame): A simulated data set 
@param cov_index (int): The column number of the problem covariate to which an extra category should be added

@returns (data.frame): The simulated data set with an extra covariate category

(Assumes Y1 is the ER)

```{r}
add_extra_covcat = function(data,cov_index){
  
  #Get id's of observations with contract 'other' in Y1
  id_other_ER = data[data$Y1==2,]$id
  
  #Select a random 90% of these observations as in the real data
  add_extra_cat = sample(id_other_ER,(0.9*length(id_other_ER))) 
  
  #Find out how many categories the problem covariate has
  ncat = length(levels(factor(data[,cov_index])))
  
  #Assign the selected observations to a new covariate category
  data[add_extra_cat,cov_index] = ncat + 1
  return(data)
}
```

```{r}
fix_extra_covcat = function(data,cov_index){
  
  #Find extra category
  ncat = length(levels(factor(data[,cov_index])))
  
  #Which is the largest group
  maxcat = which.max(summary(factor(data[,cov_index])))
  
  data[data[,cov_index]==ncat,cov_index] = maxcat 
  return(data)
}

# test2_adjusted_again = fix_extra_covcat(test2_adjusted,4)

```


## Helpfunction to create a subset of the right size and with the correct amount of measurement error for each analysis

@param iteration (int): Iteration number (to get a different data set for each of the 10 iterations per model)
@param ind (int): Number of indicators
@param cov (int): Number of covariates
@param N (int): Size of the data set
@param ME (int): Factor representing the degree of measurement error (1=0.2, 2=0.3, 3=0.5, 4=realistic)

@returns (data.frame): A subset of the right size and with the correct amount of measurement error as indicated

```{r}
create_subset = function(iteration, ind, cov_ok, cov_problem, N, ME){
  
  #If a certain data set does not exist, create it  
  if(!exists(paste0("simDat",ME,"_iteration",iteration))){
    assign(paste0("simDat",ME,"_iteration",iteration),simulate_data(iteration,ME),envir=globalenv())
  }
  
  data = get(paste0("simDat",ME,"_iteration",iteration))
  
  #Set seed to get the same data set for every model within each iteration
  set.seed(iteration) 
  select_cases = sample(1:nrow(data),N,replace=FALSE)
  
  #Select columns to return (i.e. remove some redundant columns)
  all_ind = c("Y1","Y2","Y3","Y4")
  ind = all_ind[1:ind]

  subset = data[select_cases,c("id",ind,cov_ok,cov_problem)]
  
  return(subset)
}
```



## Helpfunction to generate a Latent Gold script 

@param type (string): String indicating what type of script is generated (e.g. "LC" for regular LC and "LCT2" for LCT step 2) 
@param ind (int): Number of indicators
@param cov (int): Number of covariates
@param N (int): Size of data set
@param model_name (string): Name of the model
@param filepath_input (string):
@param filepath_output (string):

@returns (string): A string containing a Latent Gold script


```{r}
generate_script = function(type, ind, cov_ok, cov_problem, N, model_name, filepath_input, filepath_output,str=""){

  script_part1 = paste0("version = 6.0\ninfile '",filepath_input,"' \n\nmodel title '")

  #Let the number of sets of starting values depend on the size of the data set
  if(N<10000){
    sets = 3200
  } else {
    sets = 100
  }
  
  script_part2 = paste0("';
    options
    algorithm
        tolerance=1e-08 emtolerance=0.01 emiterations=1000 nriterations=1000;
    startvalues
        seed=1 sets=",sets," tolerance=1e-05 iterations=100;
    bayes
        categorical=1 variances=1 latent=1 poisson=1;
    missing includeall;
    output
    	parameters=")

  script_part3 = paste0("first standarderrors profile reorderclasses iterationdetails;
    	outfile '",filepath_output,"' classification keep=id;
    variables\n") 
     
  #Adjust some parameters depending on what type of analysis is performed
  if(type=="LC"){
    latent_var = paste0("\n\tlatent Cluster nominal 3;
    equations\n")
  } else {
    latent_var = paste0("\n\tlatent Cluster nominal 2;
    equations\n")
  }
  if(type=="LCT2"){
    caseweight = "caseweight p1;\n"
  } else {
    caseweight = ""
  }
  
  #Adjust equations depending on the number of indicators
  if(ind==2){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal;"
    dep_ind_eq = "\tY1 <- 1 + Cluster;\n\tY2 <- 1 + Cluster;"
  } else if(ind==3){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal, Y3 nominal;"
    dep_ind_eq = "\tY1 <- 1 + Cluster;\n\tY2 <- 1 + Cluster;\n\tY3 <- 1 + Cluster;"
  } else if(ind==4){
    dep_ind = "\tdependent Y1 nominal, Y2 nominal, Y3 nominal, Y4 nominal;"
    dep_ind_eq = "\tY1 <- 1 + Cluster;\n\tY2 <- 1 + Cluster;\n\tY3 <- 1 + Cluster;\n\tY4 <- 1 + Cluster;"
  }
  
  #Adjust equations depending on whether to include a covariate or not
  cov = c(cov_ok, cov_problem)

  restriction = ""
  if(is.null(cov)){
    dep_cov = ""
    latent_var_eq = "\tCluster <- 1;\n"
  }
  else{
    dep_cov = "\n\tindependent"
    latent_var_eq = "\tCluster <- 1"
    for(i in 1:length(cov)){
      if(type!="LC"&cov[i]=="SBIgroep"){
         dep_cov = paste(dep_cov,cov[i],"nominal;")
         latent_var_eq = paste0(latent_var_eq," + (ll) ",cov[i],";\n")
         restriction = "ll[1,2] = 0;"
      }
      else if(i==length(cov)){
        dep_cov = paste(dep_cov,cov[i],"nominal;")
        latent_var_eq = paste0(latent_var_eq," + ",cov[i],";\n")
      }
      else{
        dep_cov = paste(dep_cov,cov[i],"nominal,")
        latent_var_eq = paste0(latent_var_eq," + ",cov[i])
      }
    }
  }
  
  #Combine all parts of the script
  script=paste0(script_part1,model_name,script_part2,script_part3,caseweight,dep_ind,dep_cov,
                latent_var,latent_var_eq,dep_ind_eq,str,restriction,"\nend model")
  return(script)
}
```


## Helpfunction to assign the right cluster names to the right clusters 

@param results (list): Results of one particular LC, LCT or tree-MILC model

@returns (list): Same object as input, but with corrected cluster assignment if necessary 

```{r}
fix_cluster_assignment = function(type=NULL,results){
  
  #Get a list of matrices with measurement error per indicator
  ME_list = get_ME(results)
  
  #Create one matrix that contains the average values of all matrices
  summed_matrices = ME_list[[1]]
  for(j in 2:length(ME_list)){
    summed_matrices = summed_matrices + ME_list[[j]]
  }
  mean_matrix = summed_matrices/length(ME_list)
  
  #Find diagonal combinations of cluster names and store them in a data frame
  all_diagonals=data.frame()
  
  if(!is.null(type)){ #Find all possible diagonal combinations
    for(i in 1:3){
      for(j in 1:3){
       for(k in 1:3)
        if(length(unique(c(i,j,k)))==3){
          all_diagonals=rbind(all_diagonals,c(i,j,k,mean_matrix[i,1],mean_matrix[j,2],mean_matrix[k,3],
                                              sum(mean_matrix[i,1],mean_matrix[j,2],mean_matrix[k,3])))
        }
      }
    }
  }
  else { #For non-LC models: only find combinations for switched 1 and 3's, because 2 is already correct
    all_diagonals = rbind(all_diagonals,c(1,2,3,mean_matrix[1,1],mean_matrix[2,2],mean_matrix[3,3],sum(mean_matrix[1,1],mean_matrix[2,2],mean_matrix[3,3])))
  all_diagonals = rbind(all_diagonals,c(3,2,1,mean_matrix[3,1],mean_matrix[2,2],mean_matrix[1,3],sum(mean_matrix[3,1],mean_matrix[2,2],mean_matrix[1,3])))
  }
  
  colnames(all_diagonals)=c("1","2","3","d1","d2","d3","sum")
  
  #Find out which combination of diagonals yields the highest sum of diagonal values
  which_max = which.max(as.vector(all_diagonals[,7]))

  #Find out how to reassign clusters
  max_1=all_diagonals[which_max,1]
  max_2=all_diagonals[which_max,2]
  max_3=all_diagonals[which_max,3]
  reassignment = c(max_1,max_2,max_3)

  #If clusters need not to be reassigned, return original results
  if(identical(reassignment,1:3)){
    return(results)
  } 
  else {
    #Create a list to store the corrected results in (same format as input)
    to_return = list(results[[1]])
    results = results[[2]]
    
    #For tree-MILC: Don't include posterior probabilities
    if(class(results)=="list"){
      
      bootstraps_return = list()
      
      #Replace cluster values for each bootstrap sample
      for(m in 1:length(results)){
        bootstrap = results[[m]]
        for(i in 1:nrow(bootstrap)){
          if(bootstrap[i,]$cluster==max_1){
            bootstrap[i,]$cluster=1
          }
          else if(bootstrap[i,]$cluster==max_2){
            bootstrap[i,]$cluster=2
          }
          else if(bootstrap[i,]$cluster==max_3){
            bootstrap[i,]$cluster=3
          }
        }
        bootstraps_return = append(bootstraps_return,list(bootstrap))
      }
      
      to_return = append(to_return,list(bootstraps_return))
    }
      
    #For LC and LCT: Also fix posterior probabilities
    else {
    
      #Store the original posterior probabilities temporarily in a data frame 
      posteriors = data.frame(p1=results$p1,p2=results$p2,p3=results$p3)
      
      #Reassign clusters
      for(i in 1:nrow(results)){
        if(results[i,]$cluster==max_1){
          results[i,]$cluster=1
        }
        else if(results[i,]$cluster==max_2){
          results[i,]$cluster=2
        }
        else if(results[i,]$cluster==max_3){
          results[i,]$cluster=3
        }
      
        #Fix posterior probabilities
        results[i,]$p1=posteriors[i,which(reassignment==1)]
        results[i,]$p2=posteriors[i,which(reassignment==2)]
        results[i,]$p3=posteriors[i,which(reassignment==3)]
      }
        to_return = append(to_return,list(results))
    }

    return(to_return)
  }
}
```


## Helpfunction to fix scientific number notation in Latent Gold output

```{r}
fix_number_notation = function(vector){
  
  if(is.numeric(vector)){
    return(vector)
  }
  else {

    return_vec = rep(NA,length(vector))
    for(i in 1:length(vector)){
      removed_spaces = gsub(" ", "", vector[i])
      split_vec = str_split(removed_spaces, "e-")
      
      if(length(split_vec[[1]])>1){
        nominator = as.numeric(gsub(",", ".", split_vec[[1]][1]))
        denominator = as.numeric(split_vec[[1]][2])
        final_number = nominator/(10^denominator)
        return_vec[i] = final_number
      } else {
        temp_string = gsub(",", ".", split_vec[[1]][1])
        if(temp_string=="."){
          return_vec[i] = 0
        } else { 
           return_vec[i] = as.numeric(gsub(",", ".", split_vec[[1]][1]))
        }
      }
    }
    return(return_vec)
  }
}

```


## Store model info


```{r}
store_model_info = function(iteration, ind, cov_ok, cov_problem, N, ME){

  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1,  cov_problem1, N, ME, sep="-")
  # cov_ok_df = data.frame(str_split(cov_ok1,"-"))
  # cov_problem_df = data.frame(str_split(cov_problem1,"-"))
  # names(cov_ok_df) = "col1"
  # names(cov_problem_df) = "col1"
  # 
  # cov_df = rbind(cov_ok_df,cov_problem_df)
  # 
  # cov_df$col2 = NA
  # 
  # for(i in 1:nrow(cov_df)){
  #   cov_df[i,]$col2 = paste0("cov",i)
  # }
  # 
  # cov_df = spread(cov_df,col2,col1)  
  # return(cov_df)
                     
  model_info1 = data.frame(iteration=iteration,ind=ind,cov_ok=cov_ok1,cov_problem=cov_problem1)
  model_info2 = data.frame(N=N,ME=ME,id=model_name)
  model_info = cbind(model_info1,model_info2)
  
  # for(i in 1:length(cov)){
  #   model_info$cov[[i]]
  # }
  to_return = list(model_info) 

  return(to_return)
}

```

## Function to perform LC

@param iteration (int): Iteration number 
@param ind (int): Number of indicators
@param cov (int): If int: Number of covariates, if vector: Names of covariates to include
@param N (int): Size of data set
@param ME (int): Factor representing the degree of measurement error probabilities (1=0.2, 2=0.3, 3=0.5, 4=realistic)
@param folder (string): Folder to save files in

@returns (list): A list that consists of:
[[1]] Data frame with an overview of model parameters (iteration, ind, cov, N, ME)
[[2]] Data frame with model results (posterior probabilities and cluster classification for each observation)

```{r}
perform_lc = function(iteration, ind, cov_ok, cov_problem, N, ME, dat = NULL,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_4_met_covariaten\\"){

  #Store model information
  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1,  cov_problem1, N, ME, sep="-")
  to_return = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)

  #Write data set to use to file
  if(is.null(dat)){
    dat = create_subset(iteration,ind,cov_ok,cov_problem,N,ME)
  }
  else{
    dat = dat
  }

  #Adjust covariates
  if(!is.null(cov_problem)){
    for(i in cov_problem){
      cov_index = which(names(dat)==i)
      dat =   fix_extra_covcat(dat,cov_index)
    }
  }

  filepath_input = paste0(folder,"LC_",model_name,"_data.dat")
  write.table(x=dat, file = filepath_input, row.names=FALSE, quote=FALSE)
  
  #Create Latent Gold script for LC
  filepath_output = paste0(folder,paste0("LC_",model_name,"_output.dat"))
  script = generate_script("LC", ind, cov_ok,cov_problem, N, model_name, filepath_input, filepath_output)
  script_path = paste0(folder,"LC_",model_name,"_script.lgs")
  writeLines(script, script_path)
  
  #Execute Latent Gold script
  shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ',script_path,' /b'))

  #Read model output
  model_output = read.delim(filepath_output,sep="\t",dec=",")

  #Check if no warning was given
  model_lst = paste(readLines(paste0(folder,"LC_",model_name,"_script.lst")), collapse="\n")
  if(grepl("WARNING", model_lst, fixed = TRUE)){
    stop("Error")
  } 

  #Rename some columns and add data frame to return list
  setnames(model_output,old=c("Cluster.1","Cluster.2","Cluster.3","Cluster."),new=c("p1","p2","p3","cluster"))
  to_return = append(to_return,list(model_output))

  #Make sure clusters are assigned the right names
  to_return = fix_cluster_assignment(type="LC",results=to_return)
  return(to_return)
}

# lct_test = perform_lct(1,2,cov_ok="q",cov_problem=c("baanduur","SBIgroep"),1000,1)
# lc_test = perform_lc(1,2,cov_ok="q",cov_problem=c("baanduur","SBIgroep"),1000,1)

```


## Function to perform LCT adapted

@param iteration (int): Iteration number 
@param ind (int): Number of indicators
@param cov_ok (vector): Vector of covariate names (string) that are not problematic (e.g. c("q","z"))
@param cov_problem (vector): Vector of covariate names (string) that are problematic (e.g. c("a","b"))
@param N (int): Size of data set
@param ME (int): Factor representing the degree of measurement error probabilities (1=0.2, 2=0.3, 3=0.5, 4=realistic)
@param folder (string): Folder to save (intermediate) files in

@returns: A list that consists of:
[[1]] Data frame with an overview of model parameters (iteration, ind, cov_ok, cov_problem, N, ME)
[[2]] Data frame with model results

```{r}
perform_lct = function(iteration, ind, cov_ok=NULL, cov_problem=NULL, N, ME, folder="F:\\Documents\\Thesis\\Simulatie\\Voorbeeld\\"){

  #Store information about the model in the output list 
  if(is.null(cov_ok)){cov_ok1 = "null"} 
  else{cov_ok1 = paste(cov_ok, collapse="-")}
  if(is.null(cov_problem)){cov_problem1 = "null"}
  else{cov_problem1 = paste(cov_problem, collapse="-")}
  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1, cov_problem1, N, ME, sep="-")
  to_return = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)
  
  #Write data set to use to file
  dat = create_subset(iteration, ind ,cov_ok, cov_problem, N, ME)
  dat_name = paste0("LCT_",model_name,"_step1_data.dat")
  
  #'Fix' all problem covariates
  if(!is.null(cov_problem)){
    for(i in cov_problem){
      cov_index = which(names(dat)==i)
      dat = fix_extra_covcat(dat,cov_index)
    }
  }

  #Write fixed data set to file
  write.table(x=dat, file = paste0(folder,dat_name),row.names=FALSE,quote=FALSE)

  #Perform LC with 3 classes without problem covariate(s). 
  model1_output = perform_lc(iteration,ind,cov_ok,cov_problem=NULL,N,ME,folder=folder)[[2]] #Note that 'dat' is not used here, but since the same seed is used, the data set used in perform_lc should be identical.
  
  #Combine posterior probabilities for the classes 'permanent' and 'flexible' in the model output
  model1_output$p1 = 1-model1_output$p2 #Note that this is actually p1 + p3, but we call it p1 for the 'generate_script' function to work

  #The output of model 1 does not contain the problem covariates, so we add them here:
  cov_problem_indexes = which(names(dat)==cov_problem)
  for(i in cov_problem_indexes){
    model1_output[,names(dat)[i]] <- dat[,i]
  }
  
  #Write data set to use in second step to file
  dat_name = paste0("LCT_",model_name,"_step1_output.dat")
  write.table(x=model1_output, file = paste0(folder,dat_name),row.names=FALSE,quote=FALSE)
  
  #Create Latent Gold script for second LC model with problem covariate(s)
  filepath_input = paste0(folder,dat_name)
  filepath_output = paste0(folder,"LCT_",model_name,"_step2_output.dat")
  script = generate_script("LCT2", ind, cov_ok, cov_problem, N, model_name, filepath_input, filepath_output)
  script_path = paste0(folder,"LCT_",model_name,"_step2_script.lgs")
  writeLines(script, script_path)
   
  #Execute script in Latent Gold and read model output
  shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', script_path, ' /b'))
  model2_output = read.delim(filepath_output,sep="\t",dec=",")
  #Check if model is valid (i.e. does not contain a warning)
  model_lst = paste(readLines(paste0(folder,"LCT_",model_name,"_step2_script.lst")), collapse="\n")
  if(grepl("WARNING", model_lst, fixed = TRUE)){
    stop("Error in Model 2")
  }
  
  #Combine results from both models to compute final posterior probabilities and fix column names
  all_indicators = c("Y1","Y2","Y3","Y4")
  by_vector = c("id",all_indicators[1:ind],c(cov_ok,cov_problem))
  combined_output = left_join(x=model1_output,y=model2_output,by=by_vector)
  new_names = c("p1.1","p2.1","p2.2","cluster.2","cluster.1")
  setnames(combined_output,old=c("p1.y","Cluster.1","Cluster.2","Cluster.","cluster"),new=new_names)
  combined_output = combined_output[,c(by_vector,new_names)]
  combined_output$p2.2 = fix_number_notation(combined_output$p2.2)
  combined_output$p2.1 = fix_number_notation(combined_output$p2.1)
  if(!is.numeric(combined_output$cluster.2)){
    combined_output[combined_output$cluster.2==".",]$cluster.2 = 2
    combined_output$cluster.2 = as.numeric(combined_output$cluster.2)
  }
  
  #Compute posterior probabilities and combine cluster assignments from step 1 and step 2
  combined_output$p1 = combined_output$p2 = combined_output$p3 = combined_output$cluster = NA

  for(i in 1:nrow(combined_output)){
    combined_output[i,]$p2 = 1-as.numeric(combined_output[i,]$p1.1)
    combined_output[i,]$p1 = as.numeric(combined_output[i,]$p1.1)*as.numeric(combined_output[i,]$p2.1)
    combined_output[i,]$p3 = as.numeric(combined_output[i,]$p1.1)*as.numeric(combined_output[i,]$p2.2)

    if(combined_output[i,]$cluster.1==2){
      combined_output[i,]$cluster=2
    } else if((combined_output[i,]$cluster.1==1&combined_output[i,]$cluster.2==1)|(combined_output[i,]$cluster.1==3&combined_output[i,]$cluster.2==1)){
      combined_output[i,]$cluster=1
    } else if((combined_output[i,]$cluster.1==1&combined_output[i,]$cluster.2==2)|(combined_output[i,]$cluster.1==3&combined_output[i,]$cluster.2==2)){
      combined_output[i,]$cluster=3
    }
  }
  
  #Remove redundant columns
  remove_cols = c("cluster.1","cluster.2","p2.1","p2.2","p1.1")
  combined_output = combined_output[,-which(names(combined_output) %in% remove_cols)]
  to_return = append(to_return,list(combined_output))
  
  #Make sure clusters are assigned the right names
  to_return = fix_cluster_assignment(type="LCT",results=to_return)
  return(to_return)
}

# lct_test = perform_lct(1,3,cov_ok=NULL,cov_problem=c("baanduur","SBIgroep"),1000,1)

```


## Function to perform tree-MILC adapted

```{r}
perform_treeMILC_adapted = function(iteration, ind, cov_ok, cov_problem, N, ME, folder="F:\\Documents\\Thesis\\Simulatie\\Voorbeeld\\"){

  #Store model information
  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1, cov_problem1, N, ME, sep="-")
  to_return = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)
  
  #Number of bootstrap samples 
  M=5
  dat = create_subset(iteration,ind,cov_ok, cov_problem, N,ME)

  #Create list to store the results for each bootstrap sample in
  bootstrap_results = list()

  #For each bootstrap sample
  for(i in 1:M){
    set.seed(i) #Set seed to get different bootstrap samples
    sample_ids = sample(1:N,N,replace=TRUE)
    sample = dat[sample_ids,]
    sample$id = row.names(sample) #Change id to make sure it captures duplicates
    boot_name = paste0("tree_MILC_adapted_",model_name,"_boot",i)

    #Perform LC with 3 classes and combine posterior probabilities
    boot_output_step1 = perform_lc(iteration,ind,cov_ok,cov_problem=NULL,N,ME,dat = sample,folder=folder)[[2]]
    boot_output_step1$p_not2 = 1-boot_output_step1$p2 
    
    #Sample from obtained posterior membership probabilities
    boot_output_step1$imp1 = NA
    for(k in 1:N){
      boot_output_step1[k,]$imp1 = which(rmultinom(1,1,boot_output_step1[k,c("p_not2","p2")])== 1)
    }

    #Create subsets of cases with imputed values of 1 (with original indicator values) and write to file
    subset_ids = boot_output_step1[boot_output_step1$imp1==1,]$id
    subset = sample[sample$id %in% subset_ids,]
    
    
    filepath_subset = paste0(folder,"tree_MILC_adapted_",model_name,"_boot", i, "_subset.dat")
    write.table(x=subset, file =  filepath_subset,row.names=FALSE,quote=FALSE)
    

    all_indicators = c("Y1","Y2","Y3","Y4")
    by_vector = c("id",all_indicators[1:ind],c(cov_ok))
    model1_output = inner_join(x=boot_output_step1,y=sample,by=by_vector)
    setnames(model1_output,old=c("cluster"),new=c("cluster.1"))

    #Create and execute Latent Gold script for second model
    filepath_output = paste0(folder,boot_name,"_step2_output.dat")
    script = generate_script("treeMILC",ind,cov_ok,cov_problem,N,model_name,filepath_subset,filepath_output)
    script_path = paste0(folder,boot_name,"_step2_script.lgs",sep="")
    writeLines(script, script_path)
    shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', script_path, ' /b'))
    
    #Import model output
    model2_output = read.delim(paste0(folder,boot_name,"_step2_output.dat",sep=""),sep="\t",dec=",")
    #Check if model is valid (i.e. does not contain a warning)
    model_lst = paste(readLines(paste0(folder,boot_name,"_step2_script.lst")), collapse="\n")
    if(grepl("WARNING", model_lst, fixed = TRUE)){
      stop("Error in Model 2")
    }
    
    #Sample again from obtained posterior membership probabilities
    model2_output$imp2 = NA
    for (k in 1:nrow(subset)){
      model2_output[k,]$imp2 = which(rmultinom(1, 1, model2_output[k,c("Cluster.1","Cluster.2")]) == 1)
    }
    
    #Combine imputations from both models 
    combined_output = left_join(x=model1_output,y=model2_output,by=by_vector)
    combined_output$cluster = combined_output$imp1
    combined_output[(!is.na(combined_output$imp2)) & combined_output$imp2 == 1,]$cluster = 1
    combined_output[(!is.na(combined_output$imp2)) & combined_output$imp2 == 2,]$cluster = 3

    #Select and rename columns
    keep = c("p2.1","p2.2","p1.2","p1.1")
    setnames(combined_output,old=c("Cluster.1","Cluster.2","p2","p_not2"),new=keep)
    
    combined_output = combined_output[,c(by_vector,keep,"cluster")]
    bootstrap_results = append(bootstrap_results,list(combined_output))
  }
    
  to_return = append(to_return,list(bootstrap_results))
  to_return = fix_cluster_assignment(results=to_return)
  return(to_return)
}

 # r=perform_treeMILC_adapted(1,2,cov_ok="q",cov_problem="a",1000,1)
 # k=perform_treeMILC_adapted(1,2,cov_ok=c("q","a"),cov_problem=NULL,1000,1)
 # l=perform_treeMILC_adapted(1,3,cov_ok=NULL,cov_problem=NULL,1000,1)
 # m=perform_treeMILC_adapted(1,3,cov_ok=NULL,cov_problem=c("q","a"),1000,1)
 # n=perform_treeMILC_adapted(1,2,cov_ok="q",cov_problem=NULL,1000,1)
 # o=perform_treeMILC_adapted(1,3,cov_ok=NULL,cov_problem="a",1000,1)



```

## Function to perform tree-MILC

```{r}
#Function to obtain first round of imputations
impute_value_step1 = function(x){
  return(which(rmultinom(1,1,c(as.numeric(x["p1"])+as.numeric(x["p3"]),as.numeric(x["p2"])))== 1))
}

#Function to obtain second round of imputations 
impute_value_step2 = function(x){
  if(is.na(x["Cluster#1"])){
    return(NA)
  } else {
    return(which(rmultinom(1,1,c(as.numeric(x["Cluster#1"]),as.numeric(x["Cluster#2"])))== 1))
  }
}

perform_treeMILC = function(iteration, ind, cov_ok, cov_problem, N, ME, folder="F:\\Documents\\Thesis\\Simulatie\\Voorbeeld\\"){

  #Store model information
  if(is.null(cov_ok)){
    cov_ok1 = "null"
  } else {
    cov_ok1 = paste(cov_ok, collapse="-")
  }
  
  if(is.null(cov_problem)){
    cov_problem1 = "null"
  } else {
    cov_problem1 = paste(cov_problem, collapse="-")
  }

  cov = c(cov_ok1,cov_problem1)
  model_name = paste(iteration, ind, cov_ok1,  cov_problem1, N, ME, sep="-")
  to_return = store_model_info(iteration, ind, cov_ok, cov_problem, N, ME)
  
  #Number of bootstrap samples 
  M=5
  dat_org = create_subset(iteration,ind,cov_ok, cov_problem, N,ME)
  dat_org_path = paste0(folder,"tree_MILC_",model_name,"_dat_org.dat")
  fwrite(dat_org,file=dat_org_path,sep="\t")

  #Count combinations of indicators (+covariate) in the original data set
  count_dat = as.data.frame(dat_org[,-which(colnames(dat_org) %in% c("id"))] %>% group_by_all() %>% summarise(COUNT = n()))
  count_dat = count_dat[,-ncol(count_dat)]

  #Count combinations of indicators in the original data set
  count_dat_cov_ok = as.data.frame(dat_org[,-which(colnames(dat_org) %in% c("id","baanduur","SBIgroep"))] %>% group_by_all() %>% summarise(COUNT = n()))
  count_dat_cov_ok = count_dat_cov_ok[,-ncol(count_dat_cov_ok)]

  #Create help vector to combine results later
  all_indicators = c("Y1","Y2","Y3","Y4")
  by_vector = c(all_indicators[1:ind],cov_ok,cov_problem)
  by_vector_step1 = c(all_indicators[1:ind],cov_ok)

  #Create list to store the results for each bootstrap sample in
  bootstrap_results = list()

  #For each bootstrap sample
  for(i in 1:M){
    dat = dat_org
    set.seed(i) #Set seed to get different bootstrap samples
    sample = dat[sample(1:N,N,replace=TRUE),]
    boot_name = paste0("tree_MILC",model_name,"_boot",i)

    #Perform LC with 3 classes and combine posterior probabilities
    boot_output = perform_lc(iteration,ind,cov_ok,cov_problem=NULL,N,ME,dat = sample,folder=folder)

    #If model contains an error, add error to model output
    # if(boot_output[[3]]=="Error"){
    #   to_return = append(to_return,list("Error"))
    #   to_return = append(to_return,list("Error"))
    #   return(to_return)
    # }
    
    boot_output = boot_output[[2]]
    
    #Count combinations of indicators (+covariate) in the bootstrap sample
    count_boot = as.data.frame(boot_output[,-which(colnames(boot_output) %in% c("id","cluster"))] 
                          %>% group_by_all() %>% summarise(COUNT = n()))
    count_boot = count_boot[,-ncol(count_boot)]
    # print(nrow(count_boot))
    # print(nrow(count_dat))

    
    #If not all combinations are present in the bootstrap sample
    if(nrow(count_boot)!=(nrow(count_dat_cov_ok))){
      
      model_name2 = model_name
      for(zz in cov_problem){
       model_name2 = gsub(zz,"null",model_name2)
      }
      
      if(length(cov_problem)==2){ model_name2 = gsub("null-null","null",model_name2) }


      #Get data frame with parameters
      filename_lc = paste0(folder,"LC_",model_name2,"_script.lst")
      lc_lst = readChar(filename_lc,file.info(filename_lc)$size)

      lc_lst = strsplit(lc_lst,split="Regression Parameters")
      lc_lst = strsplit(lc_lst[[1]][2],split="Paired Comparisons")
      parameters_path = paste0(folder,"tree_MILC_",model_name,"_boot", i,"_parameters.dat")
      writeLines(lc_lst[[1]][1],parameters_path)
      parameters = suppressWarnings(fread(parameters_path,sep="\t",dec=","))[,1:4]
      names(parameters) = c("term1","term2","term3","coef")
      parameters$coef = as.numeric(parameters$coef)
      str = "{"
      
      for(ii in 1:nrow(parameters)){
        if(!is.na(parameters[ii,]$coef)&parameters[ii,]$coef!=0){
          str = paste(str,parameters[ii,]$coef)
        }
      }
          str = paste(str,"}")


      # remove = vector()
      # remove = which(grepl("Cluster(1)",parameters$term1,fixed=TRUE)|grepl("Y2(1)",parameters$term1,fixed=TRUE)|grepl("Y3(1)",parameters$term1,fixed=TRUE)|grepl("Y4(1)",parameters$term1,fixed=TRUE)|grepl("(1)",parameters$term3,fixed=TRUE)|(grepl("Cluster(1)",parameters$term5,fixed=TRUE)&(grepl("Y1(1)",parameters$term1,fixed=TRUE)))|(grepl("Cluster(2)",parameters$term5,fixed=TRUE)&(grepl("Y1(1)",parameters$term1,fixed=TRUE)))|(grepl("Cluster(3)",parameters$term5,fixed=TRUE)&(grepl("Y1(1)",parameters$term1,fixed=TRUE))))
      # parameters = as.data.frame(parameters[-remove,])

      #Estimate extra LC model with obtained parameters as starting values
      output_path = paste0(folder,"tree_MILC_",model_name,"_boot", i,"_dat_org_posteriors.dat")
      script = generate_script("LC",ind,cov_ok,NULL,model_name,N,filepath_input=dat_org_path,filepath_output=output_path,str)
      script_path = paste0(folder,"tree_MILC_",model_name,"_boot", i,"_dat_org_posteriors.lgs")
      writeLines(script,script_path)
      shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', script_path, ' /b'))
    
      # model_lst = paste(readLines(script_path), collapse="\n")
      # 
      # if(grepl("WARNING", model_lst, fixed = TRUE)){
      #   to_return = append(to_return,list("Error"))
      #   to_return = append(to_return,list("Error"))
      #   return(to_return)
      # }
      
      #Read model output with posterior probabilities for every observation in the original data set
      # dat = as.data.frame(fread(output_path,sep="\t",dec=","))
      
      dat = left_join(x=dat,y=as.data.frame(fread(output_path,sep="\t",dec=",")),by=c("id",by_vector_step1))
      setnames(dat,old=c("Cluster#1","Cluster#2","Cluster#3","Cluster#"),new=c("p1","p2","p3","cluster"))
      dat = fix_cluster_assignment(type="LC",list(1,dat))
      dat = dat[[2]]
      dat = dat[,-which(colnames(dat)=="cluster")] 
    } else {
      #If all combinations are present, add posterior probabilities to the observations in the original data set
      dat = left_join(x=dat,y=count_boot,by=by_vector_step1)
    }


    #Sample from obtained posterior membership probabilities
    dat$imp1 = apply(dat,1,impute_value_step1)
    dat$id = as.character(dat$id)
    
    #Create subsets of cases with imputed values of 1 (with original indicator values) and write to file
    subset_ids = dat[dat$imp1==1,]$id
    subset = dat[dat$id %in% subset_ids,]
    filepath_subset = paste0(folder,"tree_MILC",model_name,"_boot", i, "_subset.dat")
    fwrite(subset,file=filepath_subset,sep="\t")

    #Create and execute Latent Gold script for second model
    filepath_output = paste0(folder, boot_name, "_step2_output.dat")
    script = generate_script("treeMILC", ind, cov_ok, cov_problem, N, model_name, filepath_subset, filepath_output)
    script_path = paste0(folder, boot_name, "_step2_script.lgs", sep="")
    writeLines(script, script_path)
    shell(paste0('"C:/Program Files/LatentGOLDnet6.0/lg60.exe" ', script_path, ' /b'))
    
    #Import model output
    model2_output = as.data.frame(fread(paste0(folder,boot_name,"_step2_output.dat",sep=""),dec=","))

    #Check if no warning was given
    model_lst = paste(readLines(paste0(folder,boot_name,"_step2_script.lst")), collapse="\n")
    if(grepl("WARNING", model_lst, fixed = TRUE)){
      to_return = append(to_return,list("Error"))
      to_return = append(to_return,list("Error"))
      return(to_return)
    }
    
    #Add the results from the second model to the results from the first model
    count_step2 = as.data.frame(model2_output[,-which(colnames(model2_output) %in% c("id","Cluster#"))] 
                          %>% group_by_all() %>% summarise(COUNT = n()))
    count_step2 = count_step2[,-ncol(count_step2)]

    dat = left_join(x=dat,y=count_step2,by=c(all_indicators[1:ind],cov_ok,cov_problem))
  
    #Sample again from obtained posterior membership probabilities
    dat$imp2 = apply(dat,1,impute_value_step2)

    #Combine imputations from both models 
    dat$cluster = dat$imp1
    dat[dat$imp1==1 & ((!is.na(dat$imp2) & dat$imp2 == 1)),]$cluster = 1
    dat[dat$imp1==1 & ((!is.na(dat$imp2) & dat$imp2 == 2)),]$cluster = 3

    #Select and rename columns
    new_names = c("step2_p1","step2_p3")
    setnames(dat,old=c("Cluster#1","Cluster#2"),new=new_names)
    # dat = dat[,-which(colnames(dat)=="Cluster#")]

    #Fix cluster assignment (if necessary)
    dat = fix_cluster_bootstrap(dat)

    bootstrap_results = append(bootstrap_results,list(dat))
  }
  
  #Add results to final output list
  to_return = append(to_return,list(bootstrap_results))
  to_return = append(to_return,list("Good"))
  return(to_return)
}

# t = perform_treeMILC(2,2,"q","baanduur",1000,3)
t2 = perform_treeMILC(11,2,"q",NULL,1000,3)
t3 = perform_treeMILC(11,2,"q","baanduur",1000,3)
t4 = perform_treeMILC(11,2,"q",c("baanduur","SBIgroep"),1000,3)

head(t2[[2]][[5]])
head(t3[[2]][[5]])
head(t4[[2]][[5]])


# head(treeMILC_models3[[253]][[2]][[5]])
# head(treeMILC_models3[[255]][[2]][[5]])
# head(treeMILC_models3[[254]][[2]][[5]])
```


## Function to calculate entropy squared

@param results (list): Results of one particular LC or LCT model

@returns (vector): A vector containing entropy R-squared and entropy

```{r}
get_entropy = function(results){
  
  #For non-tree-MILC models
  if(class(results[[2]])!="list"){ 
    results = results[[2]] #Ignore first data frame with model information
    lc1 = sum((results$p1)*log(results$p1))
    lc1 = replace(lc1,lc1 =="NaN", 0) #In case some p's are 0
    lc2= sum((results$p2)*log(results$p2))
    lc2 = replace(lc1,lc1 =="NaN", 0)
    lc3 = sum((results$p3)*log(results$p3))
    lc3 = replace(lc1,lc1 =="NaN", 0)
    N=nrow(results)
  }
  
  #For tree-MILC models
  else { 
    N=results[[1]]$N
    p1=get_proportions(results)[1]
    p2=get_proportions(results)[2]
    p3=get_proportions(results)[3]
    
    lc1 = p1*log(p1)*(p1*N)
    lc2 = p2*log(p2)*(p2*N)
    lc3 = p3*log(p3)*(p3*N)
  }
  entropy = -(lc1+lc2+lc3)
  entropy_squared = 1-(entropy/(N*log(3)))
  entropy_vector = c(entropy_squared, entropy)
  names(entropy_vector) = c("Entropy R-squared","Entropy")
  return(entropy_vector)
}
```


## Function to calculate estimated proportions per cluster 

@param results (list): Results of one particular LC or LCT model

@returns (vector): A vector containing the estimated proportions per cluster

```{r}
get_proportions = function(results){
  results = results[[2]]   #Ignore first data frame with model information

  #For LC or LCT: Compute proportions based on posterior probabilities
  if(class(results)!="list"){        
    prop1 = sum(results$p1)
    prop2 = sum(results$p2)
    prop3 = sum(results$p3)
    proportions_vector = c(prop1,prop2,prop3)/nrow(results)
    names(proportions_vector) = 1:3
    return(proportions_vector)
  } 
  
  #For tree-MILC: Compute proportions based on imputations
  else {                    
    
    #Compute proportions per bootstrap
    prop_per_bootstrap = list()
    for(i in 1:length(results)){
      prop_per_bootstrap = append(prop_per_bootstrap,list(summary(factor(results[[i]]$cluster))/nrow(results[[i]])))
    }
  
    #Pool results
    pooled_proportions = colMeans(bind_rows(prop_per_bootstrap))   
    return(pooled_proportions)
  }
}
```


## Helpfunction to compute measurement error matrix for one indicator

@param results (data.frame): Data frame with posterior probabilities
@param ind_vec (vector): Vector containing values for one particular indicator

@returns (matrix): Measurement error matrix for one indicator

```{r}
get_ME_help = function(results,ind_vec){
  
    results$yx = ind_vec
    indicator_matrix = data.frame()
    
    for(i in 1:3){
      indicator_matrix = rbind(indicator_matrix,sum(results[results$yx==i,]$p1))
      indicator_matrix = rbind(indicator_matrix,sum(results[results$yx==i,]$p2))
      indicator_matrix = rbind(indicator_matrix,sum(results[results$yx==i,]$p3))
    }
    
    indicator_matrix = matrix(as.vector(indicator_matrix[,1]),nrow=3,ncol=3,byrow=FALSE)
    return(indicator_matrix)
    indicator_matrix = prop.table(indicator_matrix, margin = 1)
    return(indicator_matrix)
}

get_ME_help(LC_models[[1]][[2]],LC_models[[1]][[2]]$Y1)
```


## Function to compute measurement error matrix for all indicators

@param results (data.frame): Data frame with posterior probabilities
@param ind_vec (vector): Vector containing values for one particular indicator

@returns (matrix): Measurement error matrix for one indicator

```{r}
get_ME = function(results){

  #For LC and LCT: Compute ME for each indicator using the get_ME help function 
  if(class(results[[2]])!="list"){
    results = results[[2]] #Ignore first data frame with model information

    which_ind = results[,colnames(results) %in% c("Y1","Y2","Y3","Y4")]
    to_return = list()
    for(i in 1:ncol(which_ind)){
      to_return = append(to_return,list(get_ME_help(results,which_ind[,i])))
    }
    return(to_return)
  }
  
  #For tree-MILC: Compute ME for each indicator based on classification
  else {
    
    all_indicators = c("Y1","Y2","Y3","Y4")
    num_of_ind = results[[1]]$ind
    results = results[[2]]
    to_return = list()  #Create list that will contain the averages of all bootstrap sample matrices for each indicator 

    for(i in 1:num_of_ind){
      cluster_index = which(names(results[[1]])=="cluster")
      ind_index = which(names(results[[1]])==all_indicators[i])
      summed_matrix = prop.table(table(results[[1]][,cluster_index],results[[1]][,ind_index]),1)
      for(j in 2:length(results)){
        summed_matrix = summed_matrix + prop.table(table(results[[j]][,cluster_index],results[[j]][,ind_index]),1)
      }
      
      mean_matrix = summed_matrix / length(results)
      to_return = append(to_return, list(mean_matrix))
    }
    
    return(to_return)
  }
}

```



## Perform LC, LCT and tree-MILC analyis for all simulation conditions

```{r eval = FALSE}
ind = c(2:3)
N = c(1000)
ME = c(1:4)
iteration = c(1:50)
cov_problem = c("NULL","baanduur","baanduur-SBIgroep")

#Create data frame for all combinations
results_template = data.frame()
for(i in ind){
  if(i==2){
    cov_ok="q"
  } else{
    cov_ok=NULL
  }
  
  for(j in N){
    for(k in ME){
      for(l in iteration){
        for(m in cov_problem){
          name = paste(i,cov_ok,cov_problem,j,k,sep="-")
          row=c(l,i,cov_ok,m,j,k,name)
          results_template=rbind(results_template,row)
        }
      }
    }
  }
}

colnames(results_template) = c("iteration","indicator","cov_ok","cov_problem","N","ME","id")

m = 0
#Execute all LC models
LC_models3 = list()
LCT_models3 = list()
treeMILC_models3 = list()

for(l in iteration){
  for(k in ME){
    for(i in ind){
      if(i==2){
        cov_ok = "q"
      } else{
        cov_ok = NULL
    }

      for(j in N){
        for(n in cov_problem){
        m = m + 1
        name = paste0(i,"-",cov_ok,"-",n,"-",j,"-",k)
        print(paste0("--------------", m ,"---------------"))
        
          if(n=="NULL"){
            n=NULL
          } else if(n=="baanduur-SBIgroep"){
            n=c("baanduur","SBIgroep")
          }

      #   LC_models3 = append(LC_models3,list(perform_lc(l,i,cov_ok,n,j,k,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_4_met_covariaten\\LC3\\")))
      # print(paste0("LC model ",name," complete."))
      # LCT_models3 = append(LCT_models3,list(perform_lct(l,i,cov_ok,n,j,k,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_4_met_covariaten\\LCT3\\")))
      # print(paste0("LCT adapted model ",name," complete."))
      treeMILC_models3 = append(treeMILC_models3,list(perform_treeMILC(l,i,cov_ok,n,j,k,folder="F:\\Documents\\Thesis\\Simulatie\\Simulatie_4_met_covariaten\\treeMILC3\\")))
      print(paste0("treeMILC adapted model ",name," complete."))
        }
      }
    }
    
    #If a certain data set does not exist, create it  
    if(exists(paste0("simDat",k,"_iteration",l))){
      rm(list=paste0("simDat",k,"_iteration",l))
    }
  }
}

```


## Create data frame with model results

```{r}
get_results = function(models){
  
  results_df = data.frame(iteration=NA,indicator=NA,cov_ok=NA,cov_problem=NA,N=NA,ME=NA,id=NA,
                          full_id=NA,prop1=NA,prop2=NA,prop3=NA,entropy=NA,diff_ME=NA,diff_ME_diagonal_abs=NA,diff_ME_diagonal_noabs=NA)

  for(i in 1:length(models)){
    model = models[[i]]
    model1 = model[[1]]

    model_name = paste(as.numeric(model1$ind),model1$cov_ok,model1$cov_problem,as.numeric(model1$N),as.numeric(model1$ME),sep="-")
    entropy = ifelse(length(model)!=5,get_entropy(model)[1],NA)
    diff_ME = ifelse(model1$ME!=4,get_diff_ME(model),NA)
    diff_ME_diagonal_abs = get_diff_ME_diagonal_abs(model)
    diff_ME_diagonal_noabs = get_diff_ME_diagonal_noabs(model)
    
    row = c(as.numeric(model1$iteration),
            as.numeric(model1$ind),
            model1$cov_ok,
            model1$cov_problem,
            as.numeric(model1$N),
            as.numeric(model1$ME),
            model_name,full_id=model1$id,
            get_proportions(model)[1],
            get_proportions(model)[2],
            get_proportions(model)[3],
            entropy,
            diff_ME,
            diff_ME_diagonal_abs,
            diff_ME_diagonal_noabs)
    results_df[i,] = row
  }

  return(results_df)
}

LC_results=get_results(LC_models2)
LCT_results=get_results(LCT_models2)
treeMILC_results=get_results(treeMILC_models2)

```


## Create data frame with model summary

Assumes model_results name starts with LC_

```{r}
get_summary = function(type,model_results){

  convert = c("prop1","prop2","prop3","entropy","diff_ME","diff_ME_diagonal_abs","diff_ME_diagonal_noabs")
  model_results[ , convert] <- apply(model_results[ , convert], 2,function(x) as.numeric(as.character(x)))
  
  summary1 = as.data.frame(model_results %>%  group_by(indicator,cov_ok,cov_problem,N,ME,id) %>% summarise_at(c("prop1","prop2","prop3","entropy","diff_ME","diff_ME_diagonal_abs","diff_ME_diagonal_noabs"), mean))
  
  summary1$rmse_prop1 = summary1$rmse_prop2 = summary1$rmse_prop3 = NA
  
  split_df=split(model_results, model_results$id)
  nsim = length(split_df[[1]])
  
  #Compute RMSE
  for(i in 1:length(split_df)){
    summary1[summary1$id == split_df[[i]]$id[1],]$rmse_prop1 = sqrt(sum((split_df[[i]]$prop1-true_proportions[1])^2)/nsim)
    summary1[summary1$id == split_df[[i]]$id[1],]$rmse_prop2 = sqrt(sum((split_df[[i]]$prop2-true_proportions[2])^2)/nsim)
    summary1[summary1$id == split_df[[i]]$id[1],]$rmse_prop3 = sqrt(sum((split_df[[i]]$prop3-true_proportions[3])^2)/nsim)
  }
  

  summary2 = as.data.frame(model_results %>%  group_by(indicator,cov_ok,cov_problem,N,ME,id) %>% summarise_at(c("prop1","prop2","prop3","entropy","diff_ME","diff_ME_diagonal_abs","diff_ME_diagonal_noabs"), sd))[,-c(1:6)]
  names(summary2) = c("sd_prop1","sd_prop2","sd_prop3","sd_entropy","sd_diff_ME","sd_diff_ME_diagonal_abs","sd_diff_ME_diagonal_noabs")

  summary2$se_prop1 = summary2$sd_prop1/sqrt(nsim)
  summary2$se_prop2 = summary2$sd_prop2/sqrt(nsim)
  summary2$se_prop3 = summary2$sd_prop3/sqrt(nsim)
  summary = cbind(summary1,summary2)
  
  #Add model names
  new_names = rep(NA,length(names(summary)))
  
  for(i in 1:length(names(summary))){
    if(i<=6){ #Keep original names for iteration, indicator, covariate, N and ME
      new_names[i] = names(summary)[i]
    }
    if(i>6){
      new_names[i] = paste(type,names(summary)[i],sep="_")
    }
  }
  names(summary) = new_names

  return(summary)
}

LC_summary=get_summary("LC",LC_results)
LCT_summary=get_summary("LCT",LCT_results)
treeMILC_summary=get_summary("treeMILC",treeMILC_results)
```


## Combine results

```{r}
all_joined = inner_join(x=LC_summary,y=LCT_summary,by=c("id","indicator","cov_ok","cov_problem","N","ME"))
all_joined = inner_join(x=all_joined,y=treeMILC_summary,by=c("id","indicator","cov_ok","cov_problem","N","ME"))
```


## ME en heatmap dingetjes

```{r}
#Get one value that represents the difference between the true and estimated amount of measurement error  
get_diff_ME = function(results){
  
  ME = results[[1]]$ME
  ME_results = get_ME(results)
  ME_matrix = get(paste0("ME_matrix",ME))
  matrix = ME_results[[1]]
  
  for(i in 2:length(ME_results)){
    matrix = matrix + ME_results[[i]]
  }
  
  diff_ME = mean(abs((matrix/length(ME_results))-ME_matrix))
  return(diff_ME)
}
```

```{r}
get_diff_ME_diagonal_abs = function(results){
  
  ME = results[[1]]$ME
  ME_results = get_ME(results)
  ME_matrix = get(paste0("ME_matrix",ME))
  
  if(length(ME_matrix)==2){
    matrix1 = ME_results[[1]]
    if(length(ME_results)>=3){
      matrix1 = matrix1+ME_results[[3]]
    }
    
    matrix2 = ME_results[[2]]
    if(length(ME_results)==4){
      matrix2 = matrix2 + ME_results[[4]]
    }
    
    diff_sum = 0
    
    for(i in 1:3){
      diff_sum = diff_sum + abs(matrix1[i,i]/ceiling(length(ME_results)/2)-ME_matrix[[1]][i,i])
      diff_sum = diff_sum + abs(matrix2[i,i]/floor(length(ME_results)/2)-ME_matrix[[2]][i,i])

    }
    
    return(diff_sum/6)
  }
  
  else {
    matrix = ME_results[[1]]
    
    for(i in 2:length(ME_results)){
      matrix = matrix + ME_results[[i]]
    }
    
    diff_diag_1 = abs((matrix[1,1]/length(ME_results))-ME_matrix[1,1])
    diff_diag_2 = abs((matrix[2,2]/length(ME_results))-ME_matrix[2,2])
    diff_diag_3 = abs((matrix[3,3]/length(ME_results))-ME_matrix[3,3])
    
    mean_diff = mean(c(diff_diag_1,diff_diag_2,diff_diag_3))
    return(mean_diff)
  }
}
# get_diff_ME_diagonal(LC_models[[1]])
# get_diff_ME_diagonal(LC_models[[31]])

get_diff_ME_diagonal_noabs = function(results){
  
  ME = results[[1]]$ME
  ME_results = get_ME(results)
  ME_matrix = get(paste0("ME_matrix",ME))
  
  if(length(ME_matrix)==2){
    matrix1 = ME_results[[1]]
    if(length(ME_results)>=3){
      matrix1 = matrix1+ME_results[[3]]
    }
    
    matrix2 = ME_results[[2]]
    if(length(ME_results)==4){
      matrix2 = matrix2 + ME_results[[4]]
    }
    
    diff_sum = 0
    
    for(i in 1:3){
      diff_sum = diff_sum + (matrix1[i,i]/ceiling(length(ME_results)/2)-ME_matrix[[1]][i,i])
      diff_sum = diff_sum + (matrix2[i,i]/floor(length(ME_results)/2)-ME_matrix[[2]][i,i])

    }
    
    return(diff_sum/6)
  }
  
  else {
    matrix = ME_results[[1]]
    
    for(i in 2:length(ME_results)){
      matrix = matrix + ME_results[[i]]
    }
    
    diff_diag_1 = ((matrix[1,1]/length(ME_results))-ME_matrix[1,1])
    diff_diag_2 = ((matrix[2,2]/length(ME_results))-ME_matrix[2,2])
    diff_diag_3 = ((matrix[3,3]/length(ME_results))-ME_matrix[3,3])
    
    mean_diff = mean(c(diff_diag_1,diff_diag_2,diff_diag_3))
    return(mean_diff)
  }
}

```

```{r}
results_template = LC_results[,1:8]

#Get a list of matrices with for every indicator the differences between the input and estimated measurement error matrix
get_diff_matrix = function(results){
  
  ME = results[[1]]$ME
  ind = results[[1]]$ind
  ME_results = get_ME(results)
  ME_matrix = get(paste0("ME_matrix",ME))
  to_return = list()
  
  if(ME!=4){
    for(i in 1:ind){
      to_return = append(to_return,list(abs(ME_results[[i]]-ME_matrix)))
    }
  }
  
  if(ME==4){
      for(i in 1:2){
        if(ME==4){
          to_return = append(to_return,list(abs(ME_results[[i]]-ME_matrix[[i]])))  
        }
      }
          
      #Add first
      if((ME==4) & (ind>2)){
        to_return = append(to_return,list(abs(ME_results[[3]]-ME_matrix[[1]])))
      }
      if ((ME==4) & (ind>3)){
        to_return = append(to_return,list(abs(ME_results[[4]]-ME_matrix[[2]])))
      }
  }
  return(to_return)
}


#Get a list of a list of matrices and return a list with the mean matrix of every sublist
get_mean_matrix = function(list){
  num_matrices = length(list)
  num_ind = length(list[[1]])
  
  to_return = list()
  for(i in 1:num_ind){
    temp_matrix = list[[1]][[i]]
    for(j in 2:num_matrices){
      temp_matrix = temp_matrix + list[[j]][[i]]
    }
    temp_matrix = temp_matrix/num_matrices
    to_return=append(to_return,list(temp_matrix))
  }
  return(to_return)
}


#Create a single heatmap for one partiular indicator
get_ME_heatmap_help = function(model,ind,cov_ok,cov_problem,N,ME,plot_indicator){
  
    indexes = as.numeric(row.names(results_template[(results_template$ind == ind) & (results_template$cov_ok == cov_ok) & (results_template$cov_problem == cov_problem) & (results_template$N == N) & (results_template$ME == ME) ,]))
    diff_list = list()
    N = as.numeric(N)
    
 
    for(i in indexes){
      if(model=="LC"){ diff_list = append(diff_list,list(get_diff_matrix(LC_models[[i]]))) }
      if(model=="LCT"){ diff_list = append(diff_list,list(get_diff_matrix(LCT_models[[i]]))) }
      if(model=="treeMILC"){ diff_list = append(diff_list,list(get_diff_matrix(treeMILC_models[[i]]))) }
    }
    mean_diff = get_mean_matrix(diff_list)
    print("yeah")
    
    df_to_plot = as.data.frame(as.table(mean_diff[[plot_indicator]]))
    colnames(df_to_plot) = c("Model","Indicator","Difference")
    for(j in 1:3){
      levels(df_to_plot$Model)[j] = j
      levels(df_to_plot$Indicator)[j] = j
    }
    
    #Handmatige ranges
    rng = range(0,max(df_to_plot$Difference))
    # if(N==1000){
    #   if(ind==2){rng=c(0,0.21)}
    #   if(ind==3){rng=c(0,0.05)}
    #   if(ind==4){rng=c(0,0.05)}
    # 
    # }
    # else if(N==10000){
    #   if(ind==2){rng=c(0,0.12)}
    #   if(ind==3){rng=c(0,0.015)}
    #   if(ind==4){rng=c(0,0.011)}
    # }

    # print(paste0("Mean ME matrix for ",model,"-",ind,"-",cov,"-",N,"-",ME))
    # print(mean_diff)
    
    g = ggplot(df_to_plot, aes(Model,Indicator, fill = Difference)) + ggtitle(paste0("Heatmap for ",model,", indicator Y",plot_indicator)) + geom_tile()+ scale_fill_gradient2(low="lightgreen", mid="lightblue", high="red", #colors in the scale
               midpoint=mean(rng),    #same midpoint for plots (mean of the range)
               breaks=seq(0,rng[2],rng[2]/5), #breaks in the scale bar
               limits=c(0,rng[2]))

    return(g)
}

get_ME_heatmap = function(model,ind,cov_ok,cov_problem,N,ME){
  if(ind==2){
    plot1 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,1)
    plot2 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,1)
    grid.arrange(plot1, plot2, ncol=2)
  } else if(ind==3){
    plot1 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,1)
    plot2 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,2)
    plot3 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,3)
    grid.arrange(plot1, plot2,plot3, ncol=2)
  } else if(ind==4){
    plot1 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,1)
    plot2 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,2)
    plot3 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,3)
    plot4 = get_ME_heatmap_help(model,ind,cov_ok,cov_problem,N,ME,4)
    grid.arrange(plot1, plot2,plot3,plot4, ncol=2)
  }
}
```


## Tree-MILC posteriors

```{r}

get_treemilc_posteriors = function(list_of_bootstraps){
  model = list_of_bootstraps
  
  to_return = list()
   for(i in 1:length(model)){
    t = model[[i]]
    
    t$p1 = t$p3 = NA
    t$p2 = t$p1.2
    
    for(j in 1:nrow(t)){
      if(t[j,]$cluster==2){
        t[j,]$p1 = (1-t[j,]$p2)/2
        t[j,]$p3 =(1-t[j,]$p2)/2
      } else {
        t[j,]$p3 = t[j,]$p1.1 * t[j,]$p2.2
        t[j,]$p1 = t[j,]$p1.1 * t[j,]$p2.1
      }
    }
    to_return = append(to_return,list(t))
   }
  return(to_return)
}

df_prop = data.frame()
for(i in 1:length(new_list)){
  p1 = sum(new_list[[i]]$p1)/nrow(new_list[[i]])
  p2 = sum(new_list[[i]]$p2)/nrow(new_list[[i]])
  p3 = sum(new_list[[i]]$p3)/nrow(new_list[[i]])
  df_prop = rbind(df_prop,c(p1,p2,p3))
}

# cm = colMeans(df_prop)
# names(cm) = c("1","2","3")
# 
# cm
# get_proportions(treeMILC_models[[1]])

```
